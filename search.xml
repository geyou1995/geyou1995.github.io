<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis之性能优化]]></title>
    <url>%2F2021%2F01%2F12%2FRedis%E4%B9%8B%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[多级缓存架构 缓存常见问题缓存穿透说明缓存穿透是指查询一个根本不存在的数据,缓存和数据库都不会命中,如果数据库查不到则不写入缓存.这样将导致不存在的数据的每次请求都要查询数据库,失去了缓存保护后端数据库的意义. 造成原因1.自身业务代码或数据出现问题.2.一些恶意攻击、爬虫等造成大量空命中. 解决方案1.缓存空对象 12345678910111213141516171819// 去数据库获取数据等时候,如果为null,就塞一个空对象到缓存,防止连续访问,还得设置时间,如果这个key有了真实的值后再去获取String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 如果存储数据为空， 需要设置一个过期时间(300秒) if (storageValue == null) &#123; cache.expire(key, 60 * 5); &#125; return storageValue; &#125; else &#123; // 缓存非空 return cacheValue; &#125; &#125; 2.布隆过滤器 对于恶意攻击,向服务器请求大量不存在的数据导致缓存击穿,还可以使用布隆过滤器先做一次过滤,不让请求再往后端发送.核心:当布隆过滤器说某个值存在时，不一定存在;当它说这个值不存在时一定不存在. 123456// 简单总结1.首先会将缓存中的key通过一系列的hash算法，找到布隆过滤器对应数组的索引,标记'1'.2.get()数据时，也会将key进行一系列的hash算法,如果算出来的值，都是'1'，说明这个值可能存在.如果有不为'1'的那就一定不存在.// 不同担心hash冲突,布隆过滤器的数组会非常大,通常是百亿// 相较于第一种往缓存中放空对象的方式,布隆过滤器更加的节省空间. 缓存击穿（失效）说明指缓存中没有数据，数据库中有数据。一般是并发用户多，缓存时间刚好到期，缓存中读不到数据，直接去数据库读取，造成数据库压力大。 解决方案 1.设置热点数据永远不过期。2.代码里加互斥锁，缓存中没数据，第一个进入的线程获取锁从数据库读取数据，读到后再放入缓存，其他线程等待，再重新去缓存中获取。 12345678910111213141516171819// 伪代码 -- 热点缓存key重建优化String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; if(lock)&#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); &#125; // 释放锁 unlock();&#125;else&#123; // 睡眠1秒，再去缓存获取 Thread.sleep(1000); get(key); &#125; ... 缓存雪崩说明指缓存中大批数据过期，而查询数量巨大，导致数据库压力大，甚至宕机。和缓存击穿不同的是，缓存击穿是并发查同一数据。缓存雪崩时不同数据都过期了。 解决方案1.设置热点数据永不过期。2.缓存数据的过期时间随机，防止同一时间出现大量数据过期。 缓存数据库双写不一致问题说明在大并发下,同时操作数据库和缓存会存在数据不一致性. 1.双写不一致 2.读写不一致 解决方案1如果业务上能容忍,就加上缓存过期时间，可以解决大部分业务对于缓存的需求。2.如果无法容忍数据不一致,可以加读写锁保证并发读写或写写的时候按顺序排好队,读读相当无锁。3.使用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存,但是引入中间件增加系统复杂性. Redis淘汰策略a.被动删除当读写一个已经过期的key时,会触发惰性删除策略,直接删除掉这个过期key. b.主动删除由于惰性删除策略无法保证冷数据被及时删除.所以redis会定期主动淘汰一批已经过期的key. c.内存超过maxmemory限定时,触发清理策略4.0之前一共6种，4.0之后一共8种. 12345678910111213141516171819// 针对设置了过期时间的key做处理1.volatile-ttl在筛选时,会针对设置了过期时间的健值对,根据过期时间的先后进行删除,越早过期的越先被删除.2.volatile-random针对设置了过期时间的健值对随机删除.3.volatile-lru默认机制，针对设置了时间的健值对,会优先删除最近最少使用的key.（以最近时间为参考）4.volatile-lfu针对设置了时间的健值对,会优先删除最近访问次数最少的key.（以次数为参考）// 针对所有的key做处理5.allkeys-random从所有键值对中随机选择并删除数据6.allkeys-lru所有健值对中,会优先删除最近最少使用的key.（以最近时间为参考）7.allkeys-lfu所有健值对中，会优先删除最近访问次数最少的key.（以次数为参考）// 不处理8.noeviction不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息,这时只能读数据,不能写.]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis之常用架构]]></title>
    <url>%2F2021%2F01%2F07%2FRedis%E4%B9%8B%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Redis哨兵高可用架构1.sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。2.一个sentinel哨兵也是一个redis实例.3.哨兵架构下client端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过 sentinel代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端(这里面redis的client端一般都实现了订阅功能，订阅sentinel发布的节点变动消息) 12345678910111213141516171819202122// redir哨兵架构搭建步骤1.复制一份sentinel.conf文件2.将相关配置修改为如下值 port 26379 daemonize yes pidfile "/var/run/redis‐sentinel‐26379.pid" logfile "26379.log" dir "/usr/local/redis‐5.0.3/data" sentinel monitor mymaster 127.0.0.1 6379 2 --指定主节点ip,端口 2-代表指明当有多少个sentinel认为一个master失效时才失效 3.启动sentinel哨兵实例 src/redis‐sentinel sentinel‐26379.conf 4.查看sentinel的info信息,可以看到Sentinel的info里已经识别出了redis的主从信息 ... # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=2,sentinels=3 // 类似的可以多配几个哨兵 哨兵选举流程 123456当一个master服务器被sentinel看作下线状态后,该sentinel会与其他哨兵协商选出烧饼的leader进行故障转移工作.1.每个发现master下线的哨兵都可以要求其他哨兵选自己为哨兵的leader,选举先到先得.2.同时每个哨兵每次选举都会自增配置纪元（选举周期）,每个纪元只会选择一个sentine的leader.3.如果超过一半的哨兵选举某个哨兵为leader，这个哨兵就会进行故障转移操作,从存活的slave中选举新的master.整个过程类似集群选举.// 如果哨兵集群只有一个哨兵,如果master挂了，这个哨兵自动成为leader，已可以正常选举。但是为了高可用,一半推荐至少部署三个哨兵节点 1234// 哨兵模式的缺陷1.如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般.2.在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发.3.单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率. Redis高可用集群架构Redis3.0以后的版本虽然有了集群功能，提供了比以前版本的哨兵模式更高的性能和可用性，但是集群的水平扩展却比较麻烦，这里来搭建Redis集群,6个节点，采用三主三从的模式。 12// 集群模式的数据是分片存放的，各个节点的数据都不同.水平扩展可以10000个，官方推荐不要超过1000.// 至少三个主节点,从节点不支持读写，从节点的功能就是数据备份. 开始搭建准备配置文件 1234567891011121314// 这里是单机启动多个节点1.创建三个目录,每个目录下配置两个节点,8001，8002;8003，8006；8007，8008分别三组6个实例.2.修改对应的配置文件，以8001为例 daemonize yes -- 是否用守护线程启动 port 8001 -- 对应端口号 dir ./ --指定数据存放位置 cluster-enabled yes --启动集群模式 cluster-config-file nodes-8001.conf --集群节点信息，这里800x与port对应上 cluster-node-timeout 5000 --超时时间 protected-node no -- 关闭保护模式 appendonly yes requirepass gy -- 设置redis访问密码 masterauth gy -- 设置集群节点间访问密码 启动集群 12345678910111213guMacBook-Pro:redis geyou$ src/redis-server redis-cluster1/8007/redis.conf guMacBook-Pro:redis geyou$ src/redis-server redis-cluster1/8008/redis.conf guMacBook-Pro:redis geyou$ src/redis-server redis-cluster2/8001/redis.conf guMacBook-Pro:redis geyou$ src/redis-server redis-cluster2/8002/redis.conf guMacBook-Pro:redis geyou$ src/redis-server redis-cluster3/8003/redis.conf guMacBook-Pro:redis geyou$ src/redis-server redis-cluster3/8006/redis.conf ----- 501 49031 1 0 1:54下午 ?? 0:00.16 src/redis-server 127.0.0.1:8007 [cluster] 501 49035 1 0 1:55下午 ?? 0:00.11 src/redis-server 127.0.0.1:8008 [cluster] 501 49037 1 0 1:55下午 ?? 0:00.08 src/redis-server 127.0.0.1:8001 [cluster] 501 49039 1 0 1:55下午 ?? 0:00.07 src/redis-server 127.0.0.1:8002 [cluster] 501 49042 1 0 1:55下午 ?? 0:00.03 src/redis-server 127.0.0.1:8003 [cluster] 501 49044 1 0 1:55下午 ?? 0:00.02 src/redis-server 127.0.0.1:8006 [cluster] 组成集群 123456789101112131415161718192021222324252627282930313233343536// 上述还只是6个游离的实例，还未组成集群// 查看帮助文档src/redis-cli --cluster help----create：创建一个集群环境host1:port1 ... hostN:portN call：可以执行redis命令add-node：将一个节点添加到集群里，第一个参数为新节点的ip:port，第二个参数为集群中任意一个已经存在的节点的 ip:portel-node：移除一个节点reshard：重新分片check：检查集群状态// 创建集群命令redis-cli -a gy --cluster create --cluster-replicas 1 127.0.0.1:8001 127.0.0.1:8002 127.0.0.1:8003 127.0.0.1:8004 127.0.0.1:8005 127.0.0.1:8006// 成功配置信息&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:8001)M: a8fa9d463a15a5ccb373486409305f5256b2fe0c 127.0.0.1:8001 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: 11ba9f200e7f329df31d2eda0091385a98a5686d 127.0.0.1:8002 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 7cd6975e6296a1d5d4bcdea32a4622e4680975b0 127.0.0.1:8005 slots: (0 slots) slave replicates 11ba9f200e7f329df31d2eda0091385a98a5686dM: 5ed4654c5ea47c965930df7700374780450f33e4 127.0.0.1:8003 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: 875204f61ecf81f12d11e1d5884f7bce51165d53 127.0.0.1:8006 slots: (0 slots) slave replicates 5ed4654c5ea47c965930df7700374780450f33e4S: ba204ce87c14334bdc06629320eda3eddc40cd78 127.0.0.1:8004 slots: (0 slots) slave replicates a8fa9d463a15a5ccb373486409305f5256b2fe0c[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 查看集群信息 1234567// 进入一台redis客户端:src/redis-cli -a gy -c -h 127.0.0.1 -p 800111ba9f200e7f329df31d2eda0091385a98a5686d 127.0.0.1:8002@18002 master - 0 1609571581446 2 connected 5461-10922a8fa9d463a15a5ccb373486409305f5256b2fe0c 127.0.0.1:8001@18001 myself,master - 0 1609571579000 1 connected 0-54607cd6975e6296a1d5d4bcdea32a4622e4680975b0 127.0.0.1:8005@18005 slave 11ba9f200e7f329df31d2eda0091385a98a5686d 0 1609571580540 2 connected5ed4654c5ea47c965930df7700374780450f33e4 127.0.0.1:8003@18003 master - 0 1609571580000 3 connected 10923-16383875204f61ecf81f12d11e1d5884f7bce51165d53 127.0.0.1:8006@18006 slave 5ed4654c5ea47c965930df7700374780450f33e4 0 1609571581000 3 connectedba204ce87c14334bdc06629320eda3eddc40cd78 127.0.0.1:8004@18004 slave a8fa9d463a15a5ccb373486409305f5256b2fe0c 0 1609571581546 1 connected 关闭集群 12// 关闭需要逐个进行关闭，使用命令src/redis-cli -a gy -c -h 127.0.0.1 -p 800* shutdown Redis集群原理分析1231.RedisCluster将所有数据划分为16384个slots（槽位）,每个节点负责其中一部分槽位.槽位的信息存储于每个节点中.2.当Redis Cluster的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地.3.这样当客户端要查找某个key时,可以直接定位到目标节点.同时因为槽位的信息可能会存在客户端与服务器不一致的情况,还需要纠正机制来实现槽位信息的校验调整. 槽位定位算法 12Cluster默认会对key值使用'crc16'算法进行hash得到一个整数值，然后用这个整数值对16384进行取模来得到具体槽位.HASH_SLOT = CRC16(key) mod 16384 跳转重定位 121.当客户端向一个错误的节点发出了指令,该节点会发现指令的key所在的槽位并不归自己管理,这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址,告诉客户端去连这个节点去获取数据。2.客户端收到指令后除了跳转到正确的节点上去操作,还会同步更新纠正本地的槽位映射表缓存，后续所有key将使用新的槽位映射表。 Redis集群节点间的通信机制 1redis cluster节点间采取gossip协议进行通信 网络抖动 1234// 问题： 现实情况下网络可能发生抖动,突然之间部分连接不可访问,然后很快又恢复正常.这种网络抖动可能导致主从频繁切换,从 而导致数据的重新复制.// 解决： Redis Cluster 提供了一种选项cluster-node-timeout,表示当某个节点持续timeout的时间失联时，才认定该节点故障，需要进行主从切换. Redis集群选举原理 123456789101112131415// 简述当slave发现自己的master变为FAIL状态时,便尝试进行Failover(故障转移),期望成为新的matser.由于挂掉的master可能存在多个slave,所以存在多个slave竞争成为matser节点的过程.// 大致流程1.slave发现自己的master变为FAIL状态2.将自己记录的集群currentEpoch加1,并广播FAILOVER_AUTH_REQUEST 信息3.其他节点收到该信息,只有master响应,判断请求者的合法性,并发送送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack.4.尝试failover的slave收集master返回的FAILOVER_AUTH_ACK5.slave收到超过半数matser的Ack后就变成新的master -- '所以集群的节点需要至少3个,如果只有两个,一个挂了就不能选举成功'6.slave广播Pong消息通知其他集群节点，它是新的matser了.// 补充说明从节点并不是在主节点一进入FAIL状态就马上尝试发起选举,而是有一定的延迟,一定的延迟确保我们等待FAIl状态在集群中传播,slave如果立即尝试选举,其他的matser可能还没有意识到FAIL状态，可能会拒绝投票.延迟计算公式：DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms// SLAVE_RANK说明SLAVE_RANK表示slave已经从matser复制数据的总量的排名.RANk越小代表已复制的数据越新,理论上持有最新数据的slave会最先发起选举. 推荐节点数为奇数 12345奇数个master节点可以在满足选举该条件的基础上节省一个节点.例如：3个节点和4个节点挂了1个节点，都能选举新节点.挂了两个2个，就都没法选举了.所以奇数的master节点更多的是从'节省机器资源角度出发说的]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis之主从架构]]></title>
    <url>%2F2020%2F12%2F24%2FRedis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[在实际生产开发环境中,我们企业不会只部署一台Redis服务器，一方面是避免Redis单点故障,还有就是构建读写分离架构，满足读多写少的应用场景，减少Redis的服务器压力.所以来分析下Redis的主从架构. Redis主从架构 搭建123456789101112131415161718191.复制一份redis.conf文件2.将相关配置修改为如下值： port 6380 pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件 logfile "6380.log" # 日志文件 dir /usr/local/redis‐5.0.3/data/6380 # 指定数据存放目录3.配置主从复制 replicaof 127.0.0.1 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveof replica-read-only yes # 配置从节点只读4.启动从节点 redis‐server redis.conf5.连接从节点 redis‐cli ‐p 63806.测试在6379实例上写数据，查看6380是否同步过来7.可以继续配置6381端口的从节点// 按照上述，启动了6379与6380两台，6379为master,6380是slave// 先启动好6379,然后设置一些值.当启动好6380后发现，6380中已有6379的数据// 之后往6379里继续写入数据，6380这里也能接收到. Redis主从工作原理全量复制 12345678// 主要流程1.当slave连接上Master，它都会发送一个PSYNC命令给matser请求复制数据.2.master收到PSYNC命令后,会在后台进行数据持久化通过bgsave生成最新的rdb快照文件,持久化期间,会有新的数据写进来，master会把这些修改数据的请求缓存在内存里（repl buffer）。当持久化完毕后，matser会把rdb文件发送给slave.3.slave会把接收到的数据持久化成rdb然后加载到内存.4.master再将之前缓存在内存中的命令发送给slave// 注：当master与slave之间的连接由于某些原因断开,slave能够自动重连mater，如果master收到了多个slave并发请求master只会进行一次持久化，然后把一份持久化数据发送给多个并发连接的slave 部分复制 12345// 主要流程当master和slave断开重连后，一般都会对整份数据进行复制。但从redis2.8版本开始，redis改用可以支持部分数据复制的命令PSYNC去master同步数据，slave与master能够在网络连接断开重连后只进行部分数据复制(断点续传).1.master会在自己内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据.2.master和它所有的slave都维护了复制的数据下标的offset和master，当网络断开后，slave会请求master继续完成未完成的复制,从所记录的数据下标开始.3.但是如果断开链接的时间太长了，在master的缓存区里已经找不到下标了，那就会走全量复制了. 主从复制风暴 12// 如果master有很多的节点，多个节点同时复制主节点可能导致主节点压力过大// 缓解主从复制，可以使用如下结构：让部分从节点与从节点（和主节点同步的）同步数据.]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis之持久化]]></title>
    <url>%2F2020%2F12%2F21%2FRedis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本章来了解下Redis的持久化，虽然Redis是基于内存操作的，但是防止机器宕机，所有请求打到数据库，所以需要将Redis数据持久化. RDB快照在默认情况下,Redis将内存数据库快照保存在名字为dump.rdb的二进制文件中.可以对Redis进行设置,比如”N秒内数据集有M个改动”满足这个条件就自动保存一次数据集. 12345// RDB文件~vim dump.rdb :REDIS0009ú redis-ver^K255.255.255úredis-bitsÀ@ú^EctimeÂ;ºÝ_ú^Hused-memÂ`^X^P^@ú^Laof-preambleÀ^@ÿÿÕR`^QËëá// 可以看到是一堆二进制乱码,可以简单理解，恢复的时候直接把数据拉到内存，速度非常快. 12345678910111213141516171819202122232425################################ SNAPSHOTTING ################################## Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## In the example below the behavior will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## Note: you can disable saving completely by commenting out all "save" lines.## It is also possible to remove all the previously configured save# points by adding a save directive with a single empty string argument# like in the following example:## save ""save 900 1 --900秒内有1次操作，就保存一次rdbsave 300 10 --300秒内有10次操作，就保存一次rdbsave 60 10000 --60秒内有10000次操作，就保存一次rdb 出了配置上述自动保存策略,还可以手动进行rdb文件的保存.客户端执行save或bgsave可以生成dump.rdb文件，每次命令执行都会讲redis内存快照到一个新的rdb文件里，并覆盖原来的rdb快照文件. AOF重写(append-only file)RDB快照不是非常耐久,如果redis因为一些原因宕机了,那么服务器将丢失最近写入并且没有被保存到快照中的那些数据.所以引入另一种AOF持久化方式:将修改的每一条指令记录进appendonly.aof文件中. 1234567891011121314151617181920// 修改配置文件打开AOF功能# appendonly yes# appendfsync always -- 每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全# appendfsync everysec -- 每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。(默认推荐)# appendfsync no -- 从不 fsync ，将数据交给操作系统来处理。更快，也更不安全的选择// 重启redis服务器可以看到appendonly.aof//进入客户端，执行几条命令，再打开appendonly.aof查看内容*2 $6SELECT$10*3 -- *代表命令开始,3代表3个参数：set geyou111 888$3 -- 'set' 长度为3set$8 -- 'geyou111' 长度为8geyou111$3 -- '888'长度为3888 AOF也有重写的功能 12345678910111213141516171819// 比如执行5次127.0.0.1:6379&gt; incr readcount(integer) 1127.0.0.1:6379&gt; incr readcount(integer) 2127.0.0.1:6379&gt; incr readcount(integer) 3127.0.0.1:6379&gt; incr readcount(integer) 4127.0.0.1:6379&gt; incr readcount(integer) 5// 看aof文件里的内容,合成一条语句了 *3 $3 SET $2 readcount $1 5 12345// 如下两个配置可以控制AOF自动重写频率# auto‐aof‐rewrite‐min‐size 64mb //aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就 很快，重写的意义不大 # auto‐aof‐rewrite‐percentage 100 //aof文件自上一次重写后文件大小增长了100%则再次触发重写// 还可以手动重写 客户端执行bgrewriteaof RDB与AOF比较 Redis 4.0 混合持久化由于RDB方式容易丢数据，而AOF方式恢复数据比较慢。所以在Redis4.0之后提供了混合持久化. 12345678910# When rewriting the AOF file, Redis is able to use an RDB preamble in the# AOF file for faster rewrites and recoveries. When this option is turned# on the rewritten AOF file is composed of two different stanzas:## [RDB file][AOF tail]## When loading, Redis recognizes that the AOF file starts with the "REDIS"# string and loads the prefixed RDB file, then continues loading the AOF# tail.aof-use-rdb-preamble yes 1234// 原理是基于AOF的方式，必须先开启aof在AOF重写的时候，先将内存里的数据快照处理,也就是将原先RDB文件里的内容写到AOF里，这之后增量的方式还是按照AOF的方式将命令写入.这样宕机的话，大部分数据可以按照RDB的方式恢复，速度很快.剩余的一部分数据按照AOF执行原先的命令恢复.这样既兼顾了数据恢复速度也保证了数据的完整性. Redis数据备份策略1.写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48 小时的备份2.每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份3.每次copy备份的时候，都把太旧的备份给删了4.每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis之五种数据结构]]></title>
    <url>%2F2020%2F12%2F19%2FRedis%E4%B9%8B%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[安装启动123456789101112// 下载地址http://redis.io/download// 启动并指定配置文件src/redis‐server redis.conf// 验证是否启动成功ps -ef | grep redis// 进入redis客户端src/redis-cli// 退出客户端quit// 退出redis服务src/redis-cli shutdown 或者 kill 进程号 五种数据结构 String结构String结构是我们平常运用的最多的结构了.Key-String, value-String 1234567891011121314151617181920212223242526// 应用场景1.单值缓存SET key valueGET key 2.对象缓存SET key value(json格式数据)GET key这种情况需要注意Big key（大key的情况） 3.分布式锁SETNX key true...执行业务操作DEL keySETNX key true ex 10 nx (防止死锁)4.计数器比如文章点击率，key代表特定的文章唯一标识.比如key = article:readcount:&#123;文章id&#125;INCR key -- 点击加1GET key -- 获取总数5.Web集群session共享spring session + redis实现session共享 6.分布式系统全局序列号INCRBY orderId 1000 -- redis批量生成序列号提升性能 Hash结构Key-String,value-(field-value) –外层key，内存key 123456789101112// 应用场景1.对象缓存HMSET user &#123;userid&#125;:name zhuge &#123;userid&#125;:balance 18882.电商购物车 以用户id为key,商品id为field,商品数量为value. 例如购物车操作： a.添加商品-&gt;hset cart:userid-1001 goods-10088 1 b.增加数量-hincrby cart:userid-1001 goods-10088 1 c.商品总数-&gt;hlen cart:userid-1001 d.删除商品-&gt;hdel cart:userid-1001 goods-10088 e.获取购物车所有商品-&gt;hgetall cart:userid-1001 123456789// Hash结构优缺点优点：1.同类数据归类整合存储，方便数据管理2.相比String操作消耗内存与cpu更小3.相比string存储更节省空间缺点：1.过期功能 不能使用在field上，只能用在外层key上2.Redis集群架构下不适合大规模使用 List结构 1234567891011121314// 常用数据结构Stack(栈) = LPUSH + LPOP --先进后出Queue(队列) = LPUSH + RPOP --先进先出Blocking MQ(阻塞队列) = LPUSH + BRPOP// 应用场景微博和微信公众号消息流例如:我关注了MacTalk,备胎说车等大Va.MacTalk发微博，消息id为10018 -- LPUSH msg:&#123;my-id&#125; 10018b.备胎说车发微博，消息id为10086 -- LPUSH msg:&#123;my-id&#125; 10086c.查看最新消息（按照时间顺序） -- LRANGE msg:&#123;my-id&#125; 0 4这里可能有一些策略： 1.每当大V发了微博,就给关注了他的粉丝推送消息.(优化可以分批发，先给在线的发送，再依次给未在线的发送) 2.大V发的微博，就统一放到一个队列去，粉丝上线后去这个队列自己拉取消息.(这种方式，如果关注了很多大V，那么已上线就需要拉取很多大消息，还要排序,也会麻烦.) Set结构1234567891011121314151617181920212223242526272829303132333435// 应用场景1.微信小程序中奖a.点击参与抽奖加入集合SADD key &#123;userid&#125;b.查看参与抽奖所有用户SMEMBERS keyc.抽取count名中奖者SRANDMEMBER key [count] --不从集合删除筛选过的元素SPOP key [count] -- 从集合中删除筛选过的元素 2.微信微博点赞，收藏，标签a.点赞 - SADD like:&#123;消息id&#125; &#123;userId&#125;b.取消点赞 - SREM like:&#123;消息id&#125; &#123;userId&#125;c.检查用户是否点过赞 - SISMEMBER like:&#123;消息id&#125; &#123;userId&#125;d.获取点赞的用户列表 - SMEMBERS like:&#123;消息id&#125;e.获取点赞用户数 - SCADD like:&#123;消息id&#125;3.集合操作实现微博微信'关注模型'set1&#123;a,b,c&#125;; set2&#123;b,c,d&#125;; set3&#123;c,d,e&#125;SINTER set1 set2 set3 -&gt;&#123;c&#125; --交集SUNION set1 set2 set3 -&gt;&#123;a,b,c,d,e&#125;--并集SDIFF set1 set2 set3 -&gt;&#123;a&#125; -- 差集（以第一个集合为准）a.A关注的人:&#123;B,C&#125;b.B关注的人:&#123;A,C,D,E&#125;c.C关注的人：&#123;D,E,F,G&#125;则：- A和B共同关注的人：SINTER setA setB -&gt;&#123;C&#125;- A关注的人也关注：SISMEMBER Bset ESISMEMBER Cset E- A可能认识的人：SDIFF Bset Cset-&gt;&#123;A,E,F,G&#125;4.集合操作实现电商商品筛选 ZSet结构12345678910// 应用场景Zes集合实现排行榜a.点击新闻ZINCRBY hotNews:20190819 1 守护香港b.展示当日排行前十ZREVRANGE hotNews:20190819 0 9 WITHSCORESc.七日搜索榜单计算ZUNIONSTORE hotnews:20190813-20190819 7d.展示七日排行前十ZREVRANGE hotNews:20190813-20190819 0 9 WITHSCORES]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ]]></title>
    <url>%2F2020%2F12%2F14%2FRocketMQ%2F</url>
    <content type="text"><![CDATA[基本概念消息生产者（Producer）负责生产消息,一般由业务系统负责生产消息.一个消息生产者会把业务应用系统里产生的消息发送到Broker服务器.RocketMQ提供多种发送方式：同步发送、异步发送、顺序发送、单向发送（不需要Broker返回确认消息）. 消息消费者（Consumer）负责消费消息,一般是后台系统负责异步消费.一个消息消费者会从Broker服务器拉去消息、并将其提供给应用程序.有两种消费形式： 拉取式消费（应用主动调用Consumer从Broker拉取消息） 推动式消费(Broker收到消息主动推送给消费端).RocketMQ支持两种消费模式： 集群消费（相同Consumer Group的每个Consumer实例平均分摊消息） 广播消费（相同Consumer Group的每个Consumer实例都接收全量的消息） 主题（Topic）表示一类消息的集合,每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位. 同一个Topic下的数据,会分片保存到不同的Broker上,而每一个分片单位就MessageQueue,MessageQueue是生产者发送消息与消费者消费消息的最小单位. 代理服务器（Broker Server）消息中转角色，负责存储消息、转发消息.Broker Server是RocketMQ真正的业务核心，包含了多个重要的子模块. Remoting Module:整个Broker的实体,负责处理来自clients端端请求. Client Manager:负责管理客户端（Producer/Consumer）和维护Consumer端Topic订阅消息 Store Service：提供方便简单的ApI接口处理消息存储到物理硬盘和查询功能. HA Service:高可用服务,提供Master Broker和Slave Broker之间的数据同步功能. Index Service:根据特定的Message Key对投递到Broker的消息进行索引服务，以提供消息的快速查询. 名字服务（Name Server）名称服务充当路由消息的提供者.Broker Server会在启动时向所有的Name Server注册自己的服务信息.并且后续通过心跳请求的方式保证这个服务信息的实时性.生产者或消费者能够通过名字服务查找各个主题相应的Broker IP列表. 多个Name Server实例组成集群，相互独立，没有信息交换. 消息（Message）消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题Topic。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key.系统通过Message ID和Key查询消息的功能。 消息存储什么时候存储消息分布式队列因为有高可靠性的要求,所以数据需要进行持久化存储.1.MQ收到一条消息后,需要向生产者返回一个ACK响应,并将消息存储起来.2.MQ Push一条消息给消费者后,等待消费者的ACK响应,需要将消息标记为已消费.如果没有标记为已消费，MQ会不断尝试往消费者推送消息.3.MQ需要定期删除一些过期的消息,这样才能保证服务一直可用. 消息存储介质RocketMQ采用直接用磁盘文件来保存消息.磁盘随机写速度大概100KB/s,磁盘顺序写可以达到600MB/s,性能差6000倍.RocketMQ采用的顺序写,保证了消息存储的速度. 消息存储结构 刷盘机制RocketMQ需要将消息存储到磁盘上,这样才能保证断电后消息不回丢失.同时这样才能让存储到消息超过内存限制.消息在写入磁盘时,有两种写磁盘的方式： 同步刷盘: 在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程 刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写 成功的状态。 异步刷盘:在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大;当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。 注配置方式：刷盘方式是通过Broker配置文件里的flflushDiskType 参数设置的，这个参数被配置成SYNC_FLUSH、ASYNC_FLUSH中的 一个。 主从复制同步复制：同步复制是等Master和Slave都写入消息成功后才反馈给客户端写入成功的状态.在同步复制下，如果Master节点故障，Slave上有全部的数据备份，这样容易恢复数据。但是同步复制会增大数据写入的延迟，降低系统的吞量。 异步复制：异步复制是只要master写入消息成功，就反馈给客户端写入成功的状态。然后再异步的将消息复制给Slave节点.在异步复制下，系统拥有较低的延迟和较高的吞吐量。但是如果master节点故障，而有些数据没有完成复制，就会造成数据丢失。 消息重试对于普通的消息，当消费者消费消息失败后，你可以通过设置返回状态达到消息重试的结果.如何让消息重试集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置。可以有三种配置方式：返回Action.ReconsumeLater(推荐)、返回null、抛出异常。 1234567891011public class MessageListenerImpl implements MessageListener &#123; @Override public Action consume(Message message, ConsumeContext context) &#123; //处理消息 doConsumeMessage(message); //方式1：返回 Action.ReconsumeLater，消息将重试 return Action.ReconsumeLater; //方式2：返回 null，消息将重试 return null; //方式3：直接抛出异常， 消息将重试 throw new RuntimeException("Consumer Message exceotion"); &#125; &#125; 也可以不重试 12345678910111213public class MessageListenerImpl implements MessageListener &#123; @Override public Action consume(Message message, ConsumeContext context) &#123; try &#123; doConsumeMessage(message); &#125; catch (Throwable e) &#123; //捕获消费逻辑中的所有异常，并返回 Action.CommitMessage; return Action.CommitMessage; &#125; //消息处理正常，直接返回 Action.CommitMessage; return Action.CommitMessage; &#125; &#125; 死信队列当一条消息消费失败，RocketMQ就会自动进行消息重试。而如果消息超过最大重试次数，RocketMQ就会认为这个消息有问题。但是此时，RocketMQ不会立刻将这个有问题的消息丢弃，而会将其发送到这个消费者组对应的一种特殊队列：死信队列. 通常进入死信队列，意味着消息在消费处理的过程中出现比较严重的错误，无法自行恢复需要人工查看. 消息幂等消息队列 RocketMQ 的消息有可能会出现重复,例如发消息是重复、投递时重复等,需要在业务消费端自行保证幂等行. ​]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MQ基本介绍]]></title>
    <url>%2F2020%2F12%2F09%2FMQ%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[什么是MQ？MQ全称MessageQueue,即消息队列。队列是一种FIFO先进先出的数据结构。消息由生产者发送到MQ进行排列，然后按照原来的顺序交由消息的消费者进行处理。典型的MQ比如QQ和微信. MQ的作用MQ的作用主要有以下三个方面：异步能够提高系统的响应速度、吞吐量.例子:比如快递员送快递,如果快递员每一件货物都要送到客户家里，效率就会很低。所以有快递驿站，快递员只要把货物都送到驿站，由客户自己来驿站获取，这样效率就会非常高。 解耦1.服务之间进行解耦，可以减少服务之间的影响.提高系统整体的稳定性以及可扩展性.2.解耦后可以实现数据分发.生产者发送一个消息后,可以由一个或者多个消费者解进行消费，并且消费者的增加或减少对生产者没有影响.例子:电商例子,用户界面购买了某一商品，需要发送一个消息给支付系统、库存系统，他们各自去消费，不会影响主系统. 削峰提高系统的稳定性.例子：假设一个业务能成熟的最大流量请求是每秒2000，这时就可以使用MQ，每次只拉取1600的请求，剩下的放在broker慢慢消费就好，分批去消费，这样能保证系统的稳定性. MQ的缺点MQ有它的优点，当然也有它的缺点.系统可用性降低系统引入外部的依赖增多,系统的稳定性就会变差.一旦MQ宕机,对业务会产生影响.这就需要考虑MQ的高可用. 系统复杂度提高引入MQ后系统的复杂度会大大提高.以前服务之间可以进行同步的服务调用，引入MQ后，会变成异步调用，数据的链路就会变得更复杂.并且还会带来其他一些问题.比如：如何保证消费不会丢失？不会被重复调用？怎么保证消息的顺序性等问题。 消息一致性问题A系统处理完业务,通过MQ发送消息给B、C系统进行后续的业务处理.如果B系统处理成功,C系统处理失败怎么办？这就是需要考虑的如何保证消息数据处理的一致性. MQ产品特点比较 总结RabbitMQ使用于小规模场景.ActiveMQ老产品，几乎不用了.RockectMQ,几乎全场景,阿里自主研发,送给Apache。目前有开源版和商业版，商业版部分功能优于开源版.Kafka适用于日志分析,大数据采集. 由于RockectMQ功能比较完备，适用于大部分点企业，之后会专门钻研学习RockectMQ.]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring之IOC源码解析]]></title>
    <url>%2F2020%2F11%2F19%2FSpring%E4%B9%8BIOC%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上文主要概述了Spring IOC的加载流程，这片主要结合源码来分析.主要是针对注解的方式,会阐述Sping IOC涉及的核心代码代码,主要用于记录,方便之后查看能更快的回忆起来哈～ 准备配置类 12345@Configuration@ComponentScan(basePackages = &#123;"com.youga.beans"&#125;)public class MainConfig &#123; ...&#125; com.youga.beans目录下Bean实例 123456789101112131415161718@Componentpublic class Car &#123; private String name = "宝马"; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return "Car&#123;" + "name='" + name + '\'' + '&#125;'; &#125;&#125; 启动类 123456789public class AppApplication &#123; public static void main(String[] args) &#123; // IOC容器加载 AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); // 从上下文中获取Bean对象 Car car = context.getBean("car", Car.class); System.out.println(car.getName()); &#125;&#125; IOC容器的加载过程实例化容器加载上下文 1AnnotationConfigApplicationContext context=new AnnotationConfigApplicationContext（x.class）; AnnotationConfigApplicationContext的结构： 进来构造方法: 123456// 里面就3个方法public AnnotationConfigApplicationContext(Class&lt;?&gt;... componentClasses) &#123; this(); register(componentClasses); refresh(); &#125; 先来讲述 this()1234567891011121314151617public AnnotationConfigApplicationContext() &#123; // 这里隐式调用父类的构造方法，初始化DefaultListableBeanFactory // 初始化一个Bean读取器-&gt; 1.注册内置的BeanPostProcessor 2.注册相关的BeanDefinition this.reader = new AnnotatedBeanDefinitionReader(this); // 初始化一个扫描器 this.scanner = new ClassPathBeanDefinitionScanner(this); &#125;----------------- // 1.进来以后是一个无参构造方法,所以它会隐式的调用父类的无参构造方法，初始化DefaultListableBeanFactory // AnnotationConfigApplicationContext继承了GenericApplicationContext // 所以这里就构造了beanFactory-&gt;是DefaultListableBeanFactory public GenericApplicationContext() &#123; this.beanFactory = new DefaultListableBeanFactory(); &#125; DefaultListableBeanFactory的结构 123456789101112131415161718192021222324// 2.初始化一个Bean读取器// 主要做了两件事:// a.注册内置的BeanPostProcessor // b.注册相关的BeanDefinitionthis.reader = new AnnotatedBeanDefinitionReader(this);// 直接进入核心代码public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, @Nullable Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); ... // a Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8); // 注册spring内置的多个bean if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); // b beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 这里总共6个内置的Bean,以下省略 ... return beanDefs; &#125; RootBeanDefinition的结构 1234567891011// BeanDefinition主要是用来描述bean的，里面有bean的一系列信息，例如创建bean的class,作用域、是否懒加载等// registerPostProcessor就是在注册内置的BeanregisterPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME) // 点进去 private static BeanDefinitionHolder registerPostProcessor( BeanDefinitionRegistry registry, RootBeanDefinition definition, String beanName) &#123; // 为BeanDefinition设置一个Role,ROLE_INFRASTRUCTURE代表是spring内部的，不是用户定义的 definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(beanName, definition); return new BeanDefinitionHolder(definition, beanName); &#125; 12345678910// 这个方法是关键registry.registerBeanDefinition(beanName, definition);// 点进去,来到DefaultListableBeanFactory类看关键代码// beanDefinitionMap是Map&lt;String, BeanDefinition&gt;// 这里把beanName作为key, ScopedProxyMode作为value，推到map里面this.beanDefinitionMap.put(beanName, beanDefinition);// beanDefinitionNames就是一个List&lt;String&gt;,这里就是把BeanName放到List中去this.beanDefinitionNames.add(beanName);removeManualSingletonName(beanName);// 从这里可以看出springIOC的容器就是DefaultListableBeanFactory，生成的beanDefinition信息都存储在这 123// 走完 this.reader = new AnnotatedBeanDefinitionReader(this);// 看下图DefaultListableBeanFactory已经储存了内置的beanDefinition信息 1234// 3.初始化一个扫描器this.scanner = new ClassPathBeanDefinitionScanner(this);// 这个方法就是初始化scanner// todo 暂时不细看... 以上差不多就跟完了this()方法，下面来看register(componentClasses) register(componentClasses)12345678910111213141516171819202122// 传入的是一般是配置类,这里是对配置类的解析,xxxConfig.xmlregister(componentClasses);// 进入一下层,可以看到是通过this()方法构造好的读取器reader进行注册配置类public void register(Class&lt;?&gt;... componentClasses) &#123; Assert.notEmpty(componentClasses, "At least one component class must be specified"); this.reader.register(componentClasses); &#125;// 继续进入下一层,循环对配置类进行注册Bean public void register(Class&lt;?&gt;... componentClasses) &#123; for (Class&lt;?&gt; componentClass : componentClasses) &#123; registerBean(componentClass); &#125; &#125;// 继续进入registerBean()public void registerBean(Class&lt;?&gt; beanClass) &#123; doRegisterBean(beanClass, null, null, null); &#125;// 进入doRegisterBean()，真正开始做事情了～ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;T&gt; void doRegisterBean(Class&lt;T&gt; beanClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name, @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) &#123; // AnnotatedGenericBeanDefinition可以理解为一种数据结构，是用来描述Bean的 // 这里的作用就是把传入的标记了注解的类，转为AnnotatedGenericBeanDefinition数据结构，里面有一个getmetadata方法，可以拿到类上的注解 AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(beanClass); // 判断是否需要跳过注解，spring中有一个@Condition注解，当不满足条件，这个Bean就不会被解析 if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123; return; &#125; abd.setInstanceSupplier(instanceSupplier); // 解析Bean的作用域，如果没有设置的话，默认为单例 ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); abd.setScope(scopeMetadata.getScopeName()); // 获取Bean的名称 String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); // 限定符处理，不是特指@Qualifier注解，也有可能是Primary,或者是Lazy，或者是其他 // qualifiers永远都是空的，包括上面的name和instanceSupplier都一样，但是spring提供了其他方法去注册bean，就可能会传入了 if (qualifiers != null) &#123; // 可以传入qualifiers数组，所以循环处理 for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123; // primary注解优先 if (Primary.class == qualifier) &#123; abd.setPrimary(true); &#125; // Lazy注解 else if (Lazy.class == qualifier) &#123; abd.setLazyInit(true); &#125; // 其他AnnotatedGenericBeanDefinition有个Map&lt;String,AutowireCandidateQualifier&gt;属性，直接push进去 else &#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &#125; &#125; &#125; for (BeanDefinitionCustomizer customizer : definitionCustomizers) &#123; customizer.customize(abd); &#125; //这个方法用处不大，就是把AnnotatedGenericBeanDefinition数据结构和beanName封装到一个对象中 BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); // 注册Bean BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry); &#125; 1234567BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);// this.registry是BeanDefinitionRegistry接口，DefaultListableBeanFactory实现了它// 注册，最终会调用DefaultListableBeanFactory中的registerBeanDefinition方法去注册// 可以看到最终又回到了那些行代码 this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); removeManualSingletonName(beanName); 走完register(componentClasses)，可以看到beanDefinitionMap多了配置类的Bean定义 上面2个步骤主要是注册了spring内置的Bean定义以及我们自己配置类的bean定义 ,接下来我们来看最核心的方法 refresh() –这个方法很深，还没有全部看完 todo1234// 这里主要先来讲述 invokeBeanFactoryPostProcessors(beanFactory);--调用Bean工厂的后置处理器// 点进来 PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());// 继续点下去 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // Invoke BeanDefinitionRegistryPostProcessors first, if any. Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); // beanFactory是DefaultListableBeanFactory，是BeanDefinitionRegistry的实现类，所以肯定满足if if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; // 用来存放BeanFactoryPostProcessor List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); // 用来存放BeanDefinitionRegistryPostProcessor，扩展了BeanFactoryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); // 循环传进来的beanFactoryPostProcessors，正常情况下，beanFactoryPostProcessors肯定没有数据 // 因为beanFactoryPostProcessors是获得手动添加的，而不是spring扫描的 // 只有手动调用annotationConfigApplicationContext.addBeanFactoryPostProcessor(XXX)才会有数据，所以这块正常情况不会走 for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; registryProcessor.postProcessBeanDefinitionRegistry(registry); registryProcessors.add(registryProcessor); &#125; else &#123; //不是的话，就装到regularPostProcessors regularPostProcessors.add(postProcessor); &#125; &#125; // 一个临时变量，用来装载BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // 获得实现BeanDefinitionRegistryPostProcessor接口的类的BeanName:org.springframework.context.annotatio n.internalConfigurationAnnotationProcessor // 并且装入数组postProcessorNames，我理解一般情况下，只会找到一个 // 这里又有一个坑，为什么我自己创建了一个实现BeanDefinitionRegistryPostProcessor接口的类，也打上了@Component注解，配置类也加上了@Component注解，但是这里却没有拿到 // 因为直到这一步，Spring还没有去扫描，扫描是在ConfigurationClassPostProcessor类中完成的，也就是下面的第一个invokeBeanDefinitionRegistryPostProcessors方法 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; // 获得ConfigurationClassPostProcessor类，并且放到currentRegistryProcessors // ConfigurationClassPostProcessor是很重要的一个类，它实现了BeanDefinitionRegistryPostProcessor接口 // BeanDefinitionRegistryPostProcessor接口又实现了BeanFactoryPostProcessor接口 // ConfigurationClassPostProcessor是极其重要的类 // 里面执行了扫描Bean，Import，ImportResouce等各种操作 // 用来处理配置类（有两种情况 一种是传统意义上的配置类，一种是普通的bean）的各种逻辑 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); // 把name放到processedBeans，后续会根据这个集合来判断处理器是否已经被执行过了 processedBeans.add(ppName); &#125; &#125; // 处理排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 合并Processors，为什么要合并，因为registryProcessors是装载BeanDefinitionRegistryPostProcessor的 // 一开始的时候，spring只会执行BeanDefinitionRegistryPostProcessor独有的方法 // 而不会执行BeanDefinitionRegistryPostProcessor父类的方法，即BeanFactoryProcessor的方法 // 所以这里需要把处理器放入一个集合中，后续统一执行父类的方法 registryProcessors.addAll(currentRegistryProcessors); // 可以理解为执行ConfigurationClassPostProcessor的postProcessBeanDefinitionRegistry方法 // Spring热插播的体现，像ConfigurationClassPostProcessor就相当于一个组件，Spring很多事情就是交给组件去管理，如果不想用这个组件，直接把注册组件的那一步去掉就可以 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); // 因为currentRegistryProcessors是一个临时变量，所以需要清除 currentRegistryProcessors.clear(); // 再次根据BeanDefinitionRegistryPostProcessor获得BeanName，看这个BeanName是否已经被执行过了，有没有实现Ordered接口 // 如果没有被执行过，也实现了Ordered接口的话，把对象推送到currentRegistryProcessors，名称推送到processedBeans // 如果没有实现Ordered接口的话，这里不把数据加到currentRegistryProcessors，processedBeans中，后续再做处理 // 这里才可以获得我们定义的实现了BeanDefinitionRegistryPostProcessor的Bean postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; // 处理排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 合并Processors registryProcessors.addAll(currentRegistryProcessors); // 执行我们自定义的BeanDefinitionRegistryPostProcessor invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); // 清空临时变量 currentRegistryProcessors.clear(); // 上面的代码是执行了实现了Ordered接口的BeanDefinitionRegistryPostProcessor， // 下面的代码就是执行没有实现Ordered接口的BeanDefinitionRegistryPostProcessor boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); &#125; // 上面的代码是执行子类独有的方法，这里需要再把父类的方法也执行一次 invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); // regularPostProcessors装载BeanFactoryPostProcessor，执行BeanFactoryPostProcessor的方法 // 但是regularPostProcessors一般情况下，是不会有数据的，只有在外面手动添加BeanFactoryPostProcessor，才会 有数据 invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // 找到BeanFactoryPostProcessor实现类的BeanName数组 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); // 循环BeanName数组 for (String ppName : postProcessorNames) &#123; // 如果这个Bean被执行过了，跳过 if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;// 如果实现了PriorityOrdered接口，加入到priorityOrderedPostProcessors priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;// 如果实现了Ordered接口，加入到orderedPostProcessorNames orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); // 如果既没有实现PriorityOrdered，也没有实现Ordered。加入到nonOrderedPostProcessorNames &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. // 排序处理priorityOrderedPostProcessors，即实现了PriorityOrdered接口的BeanFactoryPostProcessor sortPostProcessors(priorityOrderedPostProcessors, beanFactory); // 执行priorityOrderedPostProcessors invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. // 执行实现了Ordered接口的BeanFactoryPostProcessor List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. // 执行既没有实现PriorityOrdered接口，也没有实现Ordered接口的BeanFactoryPostProcessor List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache(); &#125;// 来看下这个方法 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); 1234567891011121314151617// 这里是循环后置处理器private static void invokeBeanDefinitionRegistryPostProcessors( Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry) &#123; for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanDefinitionRegistry(registry); &#125; &#125;// 进入postProcessor.postProcessBeanDefinitionRegistry(registry)@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; ... // 直接看这个方法 processConfigBeanDefinitions(registry); &#125;// 进入processConfigBeanDefinitions(registry) 这个方法很重要～ 1.获得所有的BeanName，放入candidateNames数组.2.循环candidateNames数组，根据beanName获得BeanDefinition，判断此BeanDefinition是否已经被处理过了 3.判断是否是配置类，如果是的话.加入到configCandidates数组，在判断的时候，还会标记配置类属于Full配置类，还是Lite配置类，这里会引发一连串的知识盲点： 3.1 当我们注册配置类的时候，可以不加@Configuration注解，直接使用@Component @ComponentScan @Import @ImportResource等注解，Spring把这种配置类称之为Lite配置类， 如果加了@Configuration注解，就称之为Full配置类. 3.2 如果我们注册了Lite配置类，我们getBean这个配置类，会发现它就是原本的那个配置类，如果我们注册了Full配置类，我们getBean这个配置类，会发现它已经不是原本那个配置类了，而是已经被cgilb代理的类了. 3.3 写一个A类，其中有一个构造方法，打印出“你好”，再写一个配置类，里面有两个被@bean注解的方法，其中一个方法new了A类,并且返回A的对象，把此方法称之为getA，第二个方法又调用了getA方法，如果配置类是Lite配置类，会发现打印了两次“你好”，也就是说A类被new了两次，如果配置类是Full配置类，会发现只打印了一次“你好”，也就是说A类只被new了一次，因为这个类被cgilb代理了，方法已经被改写. 4.如果没有配置类直接返回.5.处理排序6.解析配置类，可能是Full配置类，也有可能是Lite配置类，这个小方法是此方法的核心7.在第6步的时候，只是注册了部分Bean，像 @Import @Bean等，是没有被注册的，这里统一对这些进行注册。 下面是解析配置类的过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); // 获得所有的BeanDefinition的Name,放入candidateNames String[] candidateNames = registry.getBeanDefinitionNames(); // 循环candidateNames数组 for (String beanName : candidateNames) &#123; // 根据名称获取对应的Bean定义 BeanDefinition beanDef = registry.getBeanDefinition(beanName); // 内部有两个标记位来标记是否已经处理过了 // 当我们注册配置类当时候，可以不加Configuration注解,直接使用Component ComponentScan Import ImportResou rce注解，称之为Lite配置类 // 如果加了Configuration注解，就称为Full配置类 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Bean definition has already been processed as a configuration class: " + beanDef); &#125; &#125; // 判断是否为配置类，内部判断是Full配置类，还是Lite配置类，并且做上标记 // 满足条件就加入configCandidates else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; // Return immediately if no @Configuration classes were found // 如果没有配置类就返回 if (configCandidates.isEmpty()) &#123; return; &#125; // Sort by previously determined @Order value, if applicable // 排序处理 configCandidates.sort((bd1, bd2) -&gt; &#123; int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); &#125;); // Detect any custom bean name generation strategy supplied through the enclosing application context SingletonBeanRegistry sbr = null; // DefaultListableBeanFactory最终会实现SingletonBeanRegistry接口，所以可以进入到这个if if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; // spring中可以修改默认的bean命名方式，这里就是看用户有没有自定义bean命名方式，虽然一般没有人会这么做 BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; // Parse each @Configuration class ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; //解析配置类（传统意义上的配置类或者是普通bean，核心来了） parser.parse(candidates); parser.validate(); Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; // 直到这一步才把Import的类，@Bean @ImportRosource 转换成BeanDefinition this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); candidates.clear(); ... 123456789101112131415161718192021222324252627282930// 看一下 parser.parse(candidates)public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; // 看这个方法 parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; ... &#125; // parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); protected void processConfigurationClass(ConfigurationClass configClass) throws IOException &#123; ... do &#123; // 进入该方法 sourceClass = doProcessConfigurationClass(configClass, sourceClass); &#125; while (sourceClass != null); this.configurationClasses.put(configClass, configClass); &#125; // sourceClass = doProcessConfigurationClass(configClass, sourceClass); 123456789101112131415161718192021222324252627282930313233protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; ... // Process any @ComponentScan annotations // 获得ComponentScan注解具体的内容，ComponentScan注解除了最常用的basePackage之外，还有includeFilters，excludeFilters等 Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); // 如果没有打上ComponentScan，或者被@Condition条件跳过，就不再进入这个if if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; // 循环处理componentScans for (AnnotationAttributes componentScan : componentScans) &#123; // componentScan就是@ComponentScan上的具体内容，sourceClass.getMetadata().getClassName()就是配置类的名称 Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &#123; bdCand = holder.getBeanDefinition(); &#125; if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123; // 递归调用，因为可能组件类有被@Bean标记的方法，或者组件类本身也有ComponentScan等注解 parse(bdCand.getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; ... &#125;// 看下这句解析Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); 1.定义了一个扫描器scanner.2.处理includeFilters，就是把规则添加到scanner.3.处理excludeFilters，就是把规则添加到scanner.4.解析basePackages，获得需要扫描哪些包.5.添加一个默认的排除规则：排除自身.6.执行扫描 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public Set&lt;BeanDefinitionHolder&gt; parse(AnnotationAttributes componentScan, final String declaringClass) &#123; // 扫描器，还记不记在new AnnotationConfigApplicationContext的时候，会调用AnnotationConfigApplicationContext的构造方法 // 构造方法里面有一句 this.scanner = new ClassPathBeanDefinitionScanner(this); // 当时说这个对象不重要，这里就是证明了。常规用法中，实际上执行扫描的只会是这里的scanner对象 ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean("useDefaultFilters"), this.environment, this.resourceLoader); // 判断是否重写了默认的命名规则 Class&lt;? extends BeanNameGenerator&gt; generatorClass = componentScan.getClass("nameGenerator"); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); ScopedProxyMode scopedProxyMode = componentScan.getEnum("scopedProxy"); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &#123; scanner.setScopedProxyMode(scopedProxyMode); &#125; else &#123; Class&lt;? extends ScopeMetadataResolver&gt; resolverClass = componentScan.getClass("scopeResolver"); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &#125; scanner.setResourcePattern(componentScan.getString("resourcePattern")); // addIncludeFilter addExcludeFilter,最终是往List&lt;TypeFilter&gt;里面填充数据 // TypeFilter是一个函数式接口，函数式接口在java8的时候大放异彩，只定义了一个虚方法的接口被称为函数式接口 // 当调用scanner.addIncludeFilter scanner.addExcludeFilter 仅仅把定义的规则塞进去，并没有真正去执行匹配过程 // 处理includeFilters for (AnnotationAttributes filter : componentScan.getAnnotationArray("includeFilters")) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addIncludeFilter(typeFilter); &#125; &#125; // 处理excludeFilters for (AnnotationAttributes filter : componentScan.getAnnotationArray("excludeFilters")) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addExcludeFilter(typeFilter); &#125; &#125; boolean lazyInit = componentScan.getBoolean("lazyInit"); if (lazyInit) &#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &#125; Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;(); String[] basePackagesArray = componentScan.getStringArray("basePackages"); for (String pkg : basePackagesArray) &#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &#125; // 从下面的代码可以看出ComponentScans指定扫描目标，除了最常用的basePackages，还有两种方式 // 指定basePackageClasses，就是指定多个类，只要是与这几个类同级的，或者在这几个类下级的都可以被扫描到，这种方式其实是spring比较推荐的， 因为指定basePackages没有IDE的检查，容易出错，但是指定一个类，就有IDE的检查了，不容易出错，经常会用一个空的类来作为basePackageClasses // 直接不指定，默认会把与配置类同级，或者在配置类下级的作为扫描目标 for (Class&lt;?&gt; clazz : componentScan.getClassArray("basePackageClasses")) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); &#125; if (basePackages.isEmpty()) &#123; basePackages.add(ClassUtils.getPackageName(declaringClass)); &#125; // 把规则填充到排除规则：List&lt;TypeFilter&gt;，这里就把 注册类自身当作排除规则，真正执行匹配的时候，会把自身给排除 scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &#123; @Override protected boolean matchClassName(String className) &#123; return declaringClass.equals(className); &#125; &#125;); // basePackages是一个LinkedHashSet&lt;String&gt;，这里就是把basePackages转为字符串数组的形式 return scanner.doScan(StringUtils.toStringArray(basePackages)); &#125;// 来看scanner.doScan(StringUtils.toStringArray(basePackages)); 1234567891011121314151617181920212223242526272829303132protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, "At least one base package must be specified"); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); // 循环处理basePackages for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); // 由findCandidateComponents内部可知，这里的candidate是ScannedGenericBeanDefinition // 而ScannedGenericBeanDefinition是AbstractBeanDefinition和AnnotatedBeanDefinition的之类 // 所以下面的两个if都会进入 if (candidate instanceof AbstractBeanDefinition) &#123; // 内部会设置默认值 postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; if (candidate instanceof AnnotatedBeanDefinition) &#123; // 如果是AnnotatedBeanDefinition，还会再设置一次值 AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions; &#125;]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring之IOC加载过程]]></title>
    <url>%2F2020%2F11%2F17%2FSpring%E4%B9%8BIOC%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[概述Spring框架的两大核心就是IOC(控制反转)和AOP（切面).本文主要来讲述IOC,注解的方式.首先明白IOC就是用来解决层与层之间的耦合的。 12345678// 简单理解// 通常使用某个类需要如下创建Object A = new A();... // 如果使用到的类特别多的时候，代码就会非常的冗余 // 使用IOC的方式，注解为例@Autowiredprivate Object A; IOC的加载过程流程图 1234567891011121314151617181920总体过程为：配置类xml方式或者注解方式 -&gt; 加载spring上下文（交个BeanFactory的统一信息） -&gt; 获取Bean,getBean()// 过程，主要以注解方式为例1.配置类，如下两种方式new ClassPathXmlApplicationContext("xxx.xml");-- xml方式new AnnotationConfigApplicationContext(Config.class);--注解方式2.先通过BeanDefintionReader读取@Configuration修饰的注解类，注解类上有需要扫描的类范围3.再通过BeanDefintionScanner扫描需要有效的类，被注解@Controller、@Service、@Component等修饰的类4.将这些有效类生成Beandefinition，通过BeanDefinitionRegistry将Bean定义注册到BeanDefinitionMap5.BeanFactory就是从BeanDefinitionMap获取Bean的信息，然后获取/生产Bean6.接着便是Bean的生命周期：实例化-&gt;属性赋值-&gt;初始化 实例化:通过BeanDefintion里的类信息反射生成Bean，不过这时候的Bean只是个空壳. 属性赋值：给Bean里的带有@Autowired @Value的属性赋值（这个过程可能发生循环依赖）. 初始化：调用Bean的一些initMethode destory方法，该过程中会调用很多的Aware.7.将Bean put到单例池，也就是一级缓存（key-Bean的名字，value-Bean）.8.getBean就是从一级缓存中获取. getBean("user") -&gt; Map.get()9.在这过程中还有许多的后置处理器执行BeanFactorypostProcess BeanDefinitionRegistryPostProcessBeanPostProcess 各个对象说明BeanFactory：Spring顶层核心接口，使用了简单工厂，负责生产Bean.Beandefinition：Spring顶层核心接口，Bean定义，Bean的生产方式都存储在里面BeandefinitionReader：Beandefinition的读取器,主要读取配置类（@Configuration修饰的类）BeanDefinitionSacnner：Beandefinition的扫描器，扫描有效的Bean定义（被@Controller、@Service、@Component等修饰的类）BeanDefinitionRegistry：注册Bean定义BeanFactorypostProcess：Bean工厂的后置处理器,可以用来修改Bean定义BeanDefinitionRegistryPostProcess：注册Bean定义后置处理器BeanPostProcess：Bean的后置处理器（实例化前后、填充属性前后、初始化前后） 问题解答1.描述BeanFactorySpring顶层核心接口，使用了简单工厂，负责生产Bean. 2.BeanFactory和ApplicationContext的区别？ApplicationContext可以指定配置类,可以定义更多属性，有扩展节点BeanFactorypostProcess、 BeanDefinitionRegistryPostProcessBeanFactory就是生产Bean 3.简述SpringIOC的加载过程见上文IOC加载过程 4.简述SpringBean的生命周期见上文IOC加载过程第6点 5.Spring中有哪些扩展接口及调用时机BeanFactorypostProcess –生成Beandefition后修改Bean定义BeanDefinitionRegistryPostProcess–修改注册Bean定义BeanPostProcess – 修改Bean（实例化前后、填充属性前后、初始化前后）]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[后端必备linuk操作命令]]></title>
    <url>%2F2020%2F11%2F06%2F%E5%90%8E%E7%AB%AF%E5%BF%85%E5%A4%87linuk%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[后端开发也避免不了使用linux命令，比如上服务器查看日志文件，查看服务器状态等，所以打算总结一下linux相关的命令，毕竟不是运维，无法话太多时间去深入了解学习，所以总结的都是一些基础的，也是后端程序猿必备的常用命令。Linux命令用法一般用man命令可以查看帮助信息。这里也提供了Linux中文帮助大全：http://man.linuxde.net/下面来看一些常用的命令吧～ 目录切换命令cd usr ： 切换到usr目录下cd .. (或者cd ../) ： 切换到上一层目录cd / ：切换到根目录cd~ ：切换到用户主目录cd- ：切换到上一个目录 目录操作命令mkdir 目录名称：创建目录ls ：查看目录信息find 目录 参数：寻找目录（查） 例: find /home -name “*.txt”mv 目录名称 新目录名称：修改目录名称（压缩包名也可以）mv 目录名称 目录新位置：移到目录的位置（相当于剪切，文件数量没有增加）cp -r 目录名称 目录拷贝的目录位置：拷贝目录，-r代表递归拷贝rm -f 目录名称：删除目录（还可以删除文件或压缩包） 文件操作命令（增删改查）touch 文件名称:文件的创建cat/more/less/tail 文件名称：文件的查看 cat:只能显示最后一屏内容 more:可以显示百分比，回车可以向下一行，空格可以向下一页，q可以退出查看 less:可以使用键盘上的pgup和pgDn向上或向下翻页，q结束查看 head -10:查看文件前10行，Ctrl+c结束 tail -10:查看文件的后10行 ，Ctrl+c结束vim 文件名：修改文件的内容（改） 一般步骤：vim文件 -&gt;进入文件-&gt;命令模式-&gt;按i进入编辑模式-&gt;编辑文件-&gt;按Esc进入底行模式-&gt;输入:wq 保 存并退出（输入q!代表强制退出不保存） ​ vim常用命令： 1234567891011121314151617181920212223242526272829303132333435363738394041// 移动光标1. vim 可以使用小写英文字母 h j k l 分别控制光标左 下 上 右移 2.Ctrl+b 屏幕往后移动一页3.Ctrl+f 屏幕往前移动一页 4.Ctrl+u 屏幕往后移动半页5.Ctrl+d 屏幕往前移动半页 6.shift+g == G 移动到文章的最后 7.shift+4 == $ 移动到光标所在的行尾 8.shift+6 == ^ 移动光标所在行的行首 9.w 光标跳到下个字的开头 10.e 光标跳到下个字的字尾 11.b 光标回到上个字的开头 12.#l 光标移动到改行到第‘#’个位置 13.gg 进入到文本的开始 // 删除文字 1.x 每按一次删除光标所在位置的一个字符 2.#x 例子：6x 删除光标所在位置的"后面"(包含自己在内)6个字符 3.shift+x == X 每按一次，删除光标所在位置的前一个字符 4.Shift+#x == #X 栗子 20X 删除光标所在位置的前面20个字符 5.dd 删除光标所在行 6.#dd 例子：6dd 从光标所在行开始删除6行 // 复制 1.yw 将光标所在之处到字尾的字符复制到缓冲区 2.#yw 复制#个字符到缓冲区 3.yy 复制光标所在行到缓冲区4.#yy 拷贝从光标所在的改行‘往下数’#行文字5.p 将缓冲区内的字符贴到光标所在位置 注：所有与y有关的复制命令都必须与p配合才能完成复制粘贴功能 // 替换 1.r 替换光标所在处的字符 2.R 替换光标所到之处的字符，直到按下Esc健为止 // 撤销上一次操作 1.u 回到上一个操作，按动多次‘u’可以执行多次恢复. // 更改 1.cw 更改光标所在处的字到字尾处 2.c#W 表示更改#个字 // 跳转指定行 1.ctrl+g 列出光标所在行到行号 2.#G 表示移动光标到文章的第#行行首 rm -rf 文件: 删除文件 压缩文件操作命令打包并压缩文件Linux中的打包文件一般是以.tar结尾的，压缩的文件一般是以.gz结尾的.tar -zcvf 打包压缩后的文件名 要打包的文件名z:调用gzip压缩命令进行压缩c:打包文件v:显示运行过程f:指定文件名 解压压缩包tar [-xvf] 压缩文件其中x代表解压 权限命令通过ls -l 命令我们可以查看某个目录下的文件或目录的权限. 第一列的内容信息 123456789文件类型 d:代表目录 -:代表文件 l:代表链接 linux中的权限 r:代表权限是可读，对应数字4 w:代表权限是可写，对应数字2 x:代表权限是可执行，对应数字1 文件和目录权限区别对于文件： 在linux中每个用户必须属于一个组.不能独立于组外.在linux中每个文件有所有者、所在组、其他组的概念.所有者一般指文件的创建者，谁创建了该文件，就天然的成为该文件的所有者.用 ls -l 命令可以看到文件的所有者，也可以使用 chown 用户名 文件名 来修改文件的所有者.所在组当某个用户创建了一个文件后,这个文件的所在组就是该用户所在的组 用 ls -l 命令可以看到文件的所在组，也可以使用 chgrp 组名 文件名 来修改文件所在的组.其他组除开文件的所有者和所在组的用户外,系统的其他用户都是文件的其他组. 修改文件/目录的权限的命令：chmod例子：代表aaa.txt的权限为属主有全部权限，属主所在的组有读写权限， 其他用户只有读的权限chmod u=rwx,g=rw,o=r aaa.txt 其他常用命令pwd：显示当前所在位置grep 要搜索的字符串 要搜索的文件 – color : 搜索命令，– color代表高亮ps -ef/ps aux:这两个命令都是查看当前系统正在运行进程,两者的区别是展示格式不同. 12如果想要查看特定的进程可以使用这样的格式：ps aux|grep redis (表示查看包括redis字符串的进程)如果直接使用ps(process Status)命令，回显示所有进程的状态，通常结合grep命令查看某个进程的状态 kill -9 进程的pid :杀死进程（-9 表示强制终止），先用ps 查找进程，然后kill掉shutdown -h now： 指定现在立即关机reboot：重开机 网络通信命令 123456o查看当前系统的网卡信息：ifconfigo查看与某台机器的连接情况：pingo查看当前系统的端口：netstat an 所有的连接和端口 tuln 查看正在监听TCP（t）和UDP（u）的端口 ，例如：netstat -tuln | grep LISTEN rn 查看网关 route -n]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之装饰者模式]]></title>
    <url>%2F2020%2F10%2F24%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[定义动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式比生成子类更加灵活.本质是动态组合. 结构与说明 Component:组件对象的接口，就是被装饰者的基类,也就是抽象组件.ConcreteComponent:具体的组件对象，实现组件对象接口，就是具体的被装饰者.Decorator:装饰者的父类，一个抽象类。持有Component的对象实例ConcreteDecorator：具体的装饰者，继承Decorator。 举例这里就以照相为例吧，假设刚开始相机只有一个照相功能，现在需要在照相的基础上，分别添加美颜、滤镜 功能。 1234// 抽象组件public interface Component &#123; abstract void photo();&#125; 1234567// 基本组件(被装饰者)，只有照相功能public class CameraComponent implements Component&#123; @Override public void photo() &#123; System.out.println("照相～"); &#125;&#125; 12345678// 抽象装设者类public abstract class Decorator implements Component&#123; protected Component component; public Decorator(Component component) &#123; this.component = component; &#125;&#125; 123456789101112131415161718192021222324// 具体装饰者类// 美颜public class BeautyDecorator extends Decorator&#123; public BeautyDecorator(Component component) &#123; super(component); &#125; @Override public void photo() &#123; System.out.println("增加美颜～"); component.photo(); &#125;&#125;// 滤镜public class FilterDecorator extends Decorator&#123; public FilterDecorator(Component component) &#123; super(component); &#125; @Override public void photo() &#123; System.out.println("增加滤镜～"); component.photo(); &#125;&#125; 123456789101112131415// 测试public class Test &#123; public static void main(String[] args) &#123; CameraComponent cameraComponent = new CameraComponent(); // 加美颜 BeautyDecorator beautyDecorator = new BeautyDecorator(cameraComponent); // 加滤镜 FilterDecorator filterDecorator = new FilterDecorator(beautyDecorator); filterDecorator.photo(); &#125;&#125;-------------------------------------------------增加滤镜～增加美颜～照相～ 优缺点优点:比继承灵活,更容易复用功能.缺点:会产生很多细粒度对象. 应用场景JDK里的IO流就是典型的装饰者模式.Mybatis里Excutor也应用了装饰者模式等等.]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spring解决循环依赖]]></title>
    <url>%2F2020%2F10%2F08%2Fspring%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%2F</url>
    <content type="text"><![CDATA[什么是循环依赖？循环依赖指，A依赖B，B又依赖A,它们之间形成循环依赖。或者A依赖B，B依赖C，C又依赖A. 举例 1234567891011121314// 现在有两个实例A,B,互相依赖@Componentpublic class InstanceA &#123; @Autowired private InstanceB instanceB; ...&#125;@Componentpublic class InstanceB &#123; @Autowired private InstanceA instanceA; ...&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 加载public static void loadBeanDefinition()&#123; RootBeanDefinition aRootBeanDefinition = new RootBeanDefinition(InstanceA.class); RootBeanDefinition bRootBeanDefinition = new RootBeanDefinition(InstanceB.class); beanDefinitionMap.put("instanceA",aRootBeanDefinition); beanDefinitionMap.put("instanceB",bRootBeanDefinition);&#125;// 执行方法public static void main(String[] args) throws Exception&#123; // 加载bean定义 loadBeanDefinition(); for (String key : beanDefinitionMap.keySet()) &#123; // 先创建A getBean(key); &#125;&#125;// 获取bean,bean的生命周期:实例化 -&gt; 属性赋值 -&gt; 初始化 -&gt; 存到一级缓存public static Object getBean(String beanName) throws Exception &#123; // 1.实例化 // 从bean定义中获取class信息，反射获取实例 RootBeanDefinition beanDefinition = (RootBeanDefinition)beanDefinitionMap.get(beanName); Class&lt;?&gt; beanClass = beanDefinition.getBeanClass(); // A的Bean Object instance = beanClass.newInstance(); // 2.属性赋值 // 拿到所有属性,对有Autowired注解的成员变量也调用getBean（）,递归获取 Field[] declaredFields = beanClass.getDeclaredFields(); for (Field declaredField : declaredFields) &#123; Autowired annotation = declaredField.getAnnotation(Autowired.class); // 说明属性上有Autowired注解 if(annotation != null)&#123; // 权限设置 declaredField.setAccessible(true); // 获取成员变量名 String fieldName = declaredField.getName(); // 获取B的bean对象 Object fieldObject = getBean(fieldName); // 放入对象属性 declaredField.set(instance,fieldObject); &#125;&#125; // 3.初始化 todo ... // 4.存到一级缓存 singletonObjects.put(beanName,instance); return instance; &#125; 12345678910111213141516// 测试结果:发生了循环以来问题，陷入了死循环Exception in thread "main" java.lang.StackOverflowError at java.lang.reflect.Constructor.newInstance(Constructor.java:416) at java.lang.Class.newInstance(Class.java:442) at com.youga.beans.CycleRely.getBean(CycleRely.java:74) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) at com.youga.beans.CycleRely.getBean(CycleRely.java:93) ... 如何解决循环依赖？spring是通过三级缓存来解决的。 123456// 一级缓存：用来存放完整的Bean private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);// 三级缓存：这里理解为用来处理动态代理的private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);// 二级缓存:用来存储不成熟的Bean,只是实例化，并没有赋值的bean。private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); 看spring源码 1234567891011121314151617181920212223// 总体逻辑：首先会去一级缓存中找寻，如果一级缓存中没有并且标记正在创建的Bean，就会尝试去二级缓存找寻，如果二级缓存也没有就回去三级缓存中获取singletonFactory（用来创建bean的）protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 一级缓存中获取 Object singletonObject = this.singletonObjects.get(beanName); // 判断是否是循环依赖的bean if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 一级缓存中不存在，并且是标记为正在创建的bean，尝试去二级缓存中获取 singletonObject = this.earlySingletonObjects.get(beanName); // 二级缓存里没有，就去三级缓存中获取 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject; &#125;// 那么三级缓存是什么时候放入singletonFactory对象的呢？看下面 123456789101112131415161718192021222324252627// 三级缓存中put数据// beanName,mbd(bean定义，里面有bean的相关信息)addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));// 获取bean信息,普通bean或aop的beanprotected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject; &#125;// 添加到三级缓存protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, "Singleton factory must not be null"); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; &#125; 为什么需要三级缓存？先思考下为什么需要二级缓存？因为在多线程的情况下，假设线程A正在创建Bean，还没有赋值，只是完成了实例化，若这是线程B过来获取该Bean,就会获取到不完整的Bean。所以二级缓存是用来将成熟的Bean和纯净的Bean分离开，避免读取到不完整的Bean。 为什么需要三级缓存？我们知道Bean的Aop动态代理创建时在初始化后，但是循环依赖的Bean如果使用了Aop.那就没有意义了，无法等到解决循环依赖再创建动态代理，因为这时已经注入属性了。所以如果有循环依赖需要提前使用aop.可以看到上面的earlySingletonObjects存放的是一个函数接口，不管是普通的Bean还是aop的bean，只要调用了就存在二级缓存返回。 扩展spring不能解决构造器的循环依赖，因为在实例化之前，一二三级缓存没有任何Bean的信息。此外多例的Bean也不能解决。]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot配置多数据源]]></title>
    <url>%2F2020%2F09%2F30%2FSpringBoot%E9%85%8D%E7%BD%AE%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[简述随着业务数据量增多，单个数据库已经承受不了高并发多压力。一个项目使用多个数据库来分担数据压力变得越来越重要；也可以用来做读写分离操作。下面是记录一种方式，如何在SpringBoot项目中配置多个数据源。 步骤描述在application.properties配置数据源12345678910111213141516171819202122232425262728293031323334// 如下所示这里我配置了两个数据源// 一个是本地的root数据库（mysql）// 另一个是远程的一个pro数据库（PostgreSql）root.datasource.url=jdbc:mysql://localhost:3306/test root.datasource.username=root root.datasource.password=123456 root.datasource.driverClassName=com.mysql.jdbc.Driver root.datasource.initialSize=3 root.datasource.minIdle=3 root.datasource.maxActive=55 root.datasource.maxWait=20000 root.datasource.timeBetweenEvictionRunsMillis=60000 root.datasource.minEvictableIdleTimeMillis=300000root.datasource.validationQuery=SELECT 'x' root.datasource.testWhileIdle=true root.datasource.testOnBorrow=false root.datasource.testOnReturn=false root.datasource.filters=wallpro.datasource.url=jdbc:postgresql://192.168.95.143:5432/maycur-propro.datasource.username=team1pro.datasource.password=maycurpro.datasource.driverClassName=org.postgresql.Driverpro.datasource.initialSize=3pro.datasource.minIdle=3pro.datasource.maxActive=55pro.datasource.maxWait=20000pro.datasource.timeBetweenEvictionRunsMillis=60000pro.datasource.minEvictableIdleTimeMillis=300000pro.datasource.validationQuery=SELECT 'x'pro.datasource.testWhileIdle=truepro.datasource.testOnBorrow=falsepro.datasource.testOnReturn=falsepro.datasource.filters=wall 配置参数介绍 准备数据源参数1234567891011121314151617181920// 基础配置类public class BaseDataSourceProperties &#123; private String url; private String username; private String password; private String driverClassName; private ClassLoader classLoader; private int initialSize; private int minIdle; private int maxActive; private long maxWait; private long timeBetweenEvictionRunsMillis; private long minEvictableIdleTimeMillis; private String validationQuery; private boolean testWhileIdle; private boolean testOnBorrow; private boolean testOnReturn; private String filters; private String dbType; &#125; 12345678// 这里配置pro数据库配置@Component@PropertySource("application.properties") // 指定加载的配置文件@ConfigurationProperties(prefix = ProDataSourceProperties.PREFIX) // 通过指定的前缀，绑定配置文件中的配置，该注解可以放在类上，也可以放在方法上,将配置文件对应的数据赋值给BaseDataSourceProperties里的成员public class ProDataSourceProperties extends BaseDataSourceProperties &#123; public static final String PREFIX = "pro.datasource";&#125; 1234567// 同理配置root数据库@Component@PropertySource("application.properties")@ConfigurationProperties(prefix = RootDataSourceProperties.PREFIX)public class RootDataSourceProperties extends BaseDataSourceProperties &#123; public static final String PREFIX = "root.datasource";&#125; 创建数据源配置类这里我是将Mapper分包处理，不同的数据源去扫描不同的Mapper文件去操作数据库。结构如下 开始配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 配置pro数据库的配置@Configuration // 申明为配置类@MapperScan(basePackages = "com.youga.springboot.dao.pro", sqlSessionTemplateRef = "proSessionTemplate") // 扫描该路近下的mapper文件public class ProConfigurtion &#123; @Autowired ProDataSourceProperties properties; // 注入上步骤配置好的数据源配置文件类信息 /** * 获取数据源 */ @Bean(name = "proDataSource") public DataSource getDataSource() throws SQLException &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(properties.getDriverClassName()); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setInitialSize(properties.getInitialSize()); dataSource.setMinIdle(properties.getMinIdle()); dataSource.setMaxActive(properties.getMaxActive()); dataSource.setMaxWait(properties.getMaxWait()); dataSource.setMinEvictableIdleTimeMillis(properties.getMinEvictableIdleTimeMillis()); dataSource.setValidationQuery(properties.getValidationQuery()); dataSource.setTestWhileIdle(properties.isTestWhileIdle()); dataSource.setTestOnBorrow(properties.isTestOnBorrow()); dataSource.setTestOnReturn(properties.isTestOnReturn()); dataSource.setDbType(properties.getDbType()); dataSource.setFilters(properties.getFilters()); return dataSource; &#125; // @Qualifier注解限定哪个bean应该被自动注入. // 当Spring无法判断出哪个bean应该被注入时有助于消除歧义bean的自动注入 /** * 事务管理器 */ @Bean(name = "proDataSourceTransactionManager") public DataSourceTransactionManager transactionManager(@Qualifier("proDataSource") DataSource dataSource) throws SQLException &#123; return new DataSourceTransactionManager(dataSource); &#125; /** * SqlSessionFactory是MyBatis的关键对象 * 它是个单个数据库映射关系经过编译后的内存镜像. */ @Bean(name = "proSqlSessionFactory") public SqlSessionFactory sqlSessionFactory(@Qualifier("proDataSource") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); // 配置数据源 sessionFactory.setDataSource(dataSource); // 配置执行Mapper文件存放的位置 sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources("classpath:*/com/youga/springboot/dao/pro/mapper/*.xml")); // 这里可以配置typeAliasesPackage -- 表示对应我们的实体类所在的包 return sessionFactory.getObject(); &#125; /** * SqlSessionTemplate是MyBatis-Spring的核心。 * 这个类负责管理MyBatis的SqlSession,调用MyBatis的SQL方法 */ @Bean(name = "proSessionTemplate") public SqlSessionTemplate sessionTemplate( @Qualifier("proSqlSessionFactory") SqlSessionFactory sqlSessionFactory) &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 同理配置root数据库配置@Configuration@MapperScan(basePackages = "com.youga.springboot.dao.root", sqlSessionTemplateRef = "rootSessionTemplate")public class RootConfiguration &#123; @Autowired RootDataSourceProperties properties; @Bean(name = "rootDataSource") public DataSource getDataSource() throws SQLException &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(properties.getDriverClassName()); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setInitialSize(properties.getInitialSize()); dataSource.setMinIdle(properties.getMinIdle()); dataSource.setMaxActive(properties.getMaxActive()); dataSource.setMaxWait(properties.getMaxWait()); dataSource.setMinEvictableIdleTimeMillis(properties.getMinEvictableIdleTimeMillis()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); dataSource.setValidationQuery(properties.getValidationQuery()); dataSource.setTestWhileIdle(properties.isTestWhileIdle()); dataSource.setTestOnBorrow(properties.isTestOnBorrow()); dataSource.setTestOnReturn(properties.isTestOnReturn()); dataSource.setDbType(properties.getDbType()); dataSource.setFilters(properties.getFilters()); return dataSource; &#125; @Bean(name = "rootDataSourceTransactionManager") public DataSourceTransactionManager transactionManager(@Qualifier("rootDataSource") DataSource dataSource) throws SQLException &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = "rootSqlSessionFactory") public SqlSessionFactory sqlSessionFactory(@Qualifier("rootDataSource") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(dataSource); sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources("classpath:*/com/youga/springboot/dao/root/mapper/*.xml")); return sessionFactory.getObject(); &#125; @Bean(name = "rootSessionTemplate") public SqlSessionTemplate sessionTemplate( @Qualifier("rootSqlSessionFactory") SqlSessionFactory sqlSessionFactory) &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 测试1234567891011 @GetMapping("/dateSourceTest") @ResponseBody public String dateSourceTest() &#123; List&lt;ProcessLogDO&gt; processLogDOS = processLogMapper.select(); UserDO userDO = userMapper.select(2); return "proData:" + JSON.toJSONString(processLogDOS.get(0)) +"rootData:" + JSON.toJSONString(userDO);&#125;---------------结果---------------proData:&#123;"entCode":"EC16040611HZCQGW","formDataCode":"BX1907081H2S2SCG"&#125;rootData:&#123;"age":27,"ext":"北冥神功","id":2,"name":"虚竹"&#125;]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mybaits拦截器实现水平分表]]></title>
    <url>%2F2020%2F09%2F26%2F%E6%B0%B4%E5%B9%B3%E5%88%86%E8%A1%A8%E4%B9%8Bmybatis%E6%8B%A6%E6%88%AA%E5%99%A8%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[需求背景最近项目中的几张表数据行超过了1000万行，所以需要对这些表进行水平分表，提高数据查询的性能。可选的方案有sharding-jdbc中间件还有就是Mybatis拦截器。由于个别表数据涉及了复杂的sql查询，可能会有意想不到的坑，所以决定采用Mybatis拦截器的方式。所以决定记录下来实现过程。 分表思路这里我需要分表的表名为process_log,这里不是根据正常的id字段去分表（因为这张表连id字段都没有…）,而是选择这张表的唯一字段form_data_code来作为分表字段，将form_data_code字段值进行hashCode()然后进行取模。目前这张表的数据足足5000多万，考虑之后还会增加，需要将表数据控制在百万级内，所以你决定分表20张。先来了解一下Mybatis拦截器… Mybaits拦截器对四大接口进行拦截 Executor:是mybatis的内部执行器，它通过调用StatementHandler来操作数据库StatementHandler:是mybatis直接和数据库执行sql脚本的对象ResultSetHandler:是mybaits把ResultSet集合映射成POJO的接口对象ParameterHandler:是mybatis实现sql入参设置的对象 Interceptor 接口mtbatis拦截器必须实现Interceptor接口 12345678public interface Interceptor &#123; // 拦截器执行的逻辑方法 Object intercept(Invocation invocation) throws Throwable; // 用来封装目标对象。可以返回目标对象本身也可以根据实际需要，创建一个代理对象 Object plugin(Object target); // 在Mybatis进行配置插件的时候可以配置自定义相关属性 void setProperties(Properties properties);&#125; 12345678910// @Intercepts注解参数数名// Intercepts 拦截器: 标识我的类是一个拦截器// Signature 署名: 则是指明我们的拦截器需要拦截哪一个接口的哪一个方法// type 对应四类接口中的某一个，比如是 StatementHandler// method 对应接口中的哪类方法，比如 StatementHandler 的 prepare 方法// args对应接口中的哪一个方法，方法参数@Intercepts(@Signature(type = StatementHandler.class,method = "prepare",args = &#123;Connection.class,Integer.class&#125;))public class ShardTableInterceptor implements Interceptor &#123; // todo &#125; 实战实现1.实现自定义注解 123456789101112131415@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface SegmentTable &#123; /** * 表名 */ String tableName(); /** * 算法策略 */ Class strategyClazz();&#125;// 需要分表的table的Mapper接口@SegmentTable(tableName = "process_log", strategyClazz = ProcessLogStrategy.class)public interface ProcessLogMapper &#123;// todo&#125; 2.使用策略模式实现算法 123456789public interface ShardTableStrategy &#123; /** * 分表算法 * * @param statementHandler * @return */ String shardAlgorithm(StatementHandler statementHandler);&#125; 1234567891011public class ShardTableContext &#123; private ShardTableStrategy tableStrategy; public ShardTableContext(ShardTableStrategy tableStrategy) &#123; this.tableStrategy = tableStrategy; &#125; public String doShardAlgorithm(StatementHandler statementHandler)&#123; return tableStrategy.shardAlgorithm(statementHandler); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// process_log表算法public class ProcessLogStrategy implements ShardTableStrategy &#123; private static final Logger logger = LoggerFactory.getLogger(ProcessLogStrategy.class); /** * 分表20张 */ public final static Integer PROCESS_LOG_TABLE_NUM = 20; /** * 特殊处理字段 */ private final static String PROCESS_LOG_TABLE_CONFIRM_INDEX = "subTableConfirmIndex"; /** * 分表字段 */ private final static String PROCESS_LOG_TABLE_SUB_FIELD = "formDataCode"; private final static String PROCESS_LOG_BLANK_INDEX = ""; @Override public String shardAlgorithm(StatementHandler statementHandler) &#123; if (statementHandler == null) &#123; logger.error("statementHandler is null"); return PROCESS_LOG_BLANK_INDEX; &#125; BoundSql boundSql = statementHandler.getBoundSql(); Object parameterObject = boundSql.getParameterObject(); Map param2ValeMap = JSONObject.parseObject(JSON.toJSONString(parameterObject), Map.class); if (MapUtils.isEmpty(param2ValeMap)) &#123; return PROCESS_LOG_BLANK_INDEX; &#125; // 特殊处理foreach循环语句 Object confirmIndexValue = param2ValeMap.get(PROCESS_LOG_TABLE_CONFIRM_INDEX); if (confirmIndexValue != null) &#123; return SHARD_TABLE_INDEX_LINE + confirmIndexValue; &#125; Object subFieldValue = param2ValeMap.get(PROCESS_LOG_TABLE_SUB_FIELD); return SHARD_TABLE_INDEX_LINE + Math.abs(subFieldValue.hashCode() % PROCESS_LOG_TABLE_NUM); &#125;&#125; 3.拦截器intercept()执行逻辑 12345678910111213141516171819202122232425@Override public Object intercept(Invocation invocation) throws Throwable &#123; StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); // 全局操作读对象 MetaObject metaObject = MetaObject.forObject(statementHandler, SystemMetaObject.DEFAULT_OBJECT_FACTORY, SystemMetaObject.DEFAULT_OBJECT_WRAPPER_FACTORY, new DefaultReflectorFactory()); // @SegmentTable -- 只拦截有注解的Mapper SegmentTable segmentTable = getSegmentTable(metaObject); if (segmentTable == null) &#123; return invocation.proceed(); &#125; // 1.对value进行算法 -&gt; 确定表名 Class strategyClazz = segmentTable.strategyClazz(); ShardTableStrategy strategy = (ShardTableStrategy) strategyClazz.newInstance(); String index = new ShardTableContext(strategy).doShardAlgorithm(statementHandler); logger.info("ShardTableInterceptor segmentTable=&#123;&#125;,index=&#123;&#125;", JSON.toJSONString(segmentTable), index); // 2.替换表名 // 获取原始sql String tableName = segmentTable.tableName(); String sql = (String) metaObject.getValue(BOUND_SQL_NAME); metaObject.setValue(BOUND_SQL_NAME, sql.replaceFirst(tableName, tableName + index)); return invocation.proceed(); &#125; 总结遇到的问题1.这张表用了多表关联现在终于明白，为什么要单表查询了，许多数据库性能的优化，都需要在单表的基础上才能更好的实施，所以现在的做法是，首先将多表关联的部分，采用单表查询在业务里处理掉. 2.分页插件pagehelper导致自定义插件无效项目系统里也用了mybatis的分页插件pagehelper,pagehelper的intercept方法中没有invocation.proceed()，所以导致自定义的拦截器失效，没有传递下去。所以需要调整注册顺序。– 参考http://xtong.tech/2018/08/01/MyBatis%E6%8B%A6%E6%88%AA%E5%99%A8%E5%9B%A0pagehelper%E8%80%8C%E5%A4%B1%E6%95%88%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/ 3.迁移老数据分表首先要做的就是老数据的迁移，由于这里是根据Java的hashcode()计算关键字段，数据库的函数也要同一种hash算法，这里用的数据库是postgreSql,里面提供了一些hash算法但是和java的不同，因为要用阿里的DataWorks迁移，经过调研，Pg可以提供自定义算法，所以可以创建于JAVA hashCode()相同的自定义算法，这样就可以保证数据的迁移。 123456789101112131415161718// 自定义java hashCode算法DROP FUNCTION IF EXISTS hash_code(text);CREATE FUNCTION hash_code(text) RETURNS integer LANGUAGE plpgsqlAS$$DECLARE i integer := 0; DECLARE h bigint := 0;BEGIN FOR i IN 1..length($1) LOOP h = (h * 31 + ascii(substring($1, i, 1))) &amp; 4294967295; END LOOP; RETURN cast(cast(h AS bit(32)) AS int4);END;$$;]]></content>
      <categories>
        <category>Java开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之策略模式]]></title>
    <url>%2F2020%2F09%2F19%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[定义定义一系列的算法，把他们一个个封装起来，并且使它们可相互替换。 结构及说明 Strategy:策略接口，用来约束一系列具体的策略算法。Context使用这个接口来调用具体的算法。ConcreteStrategy:具体的策略实现，也就是具体的算法实现。Context:上下文,负责和具体的策略类交互通常会持有一个正常的策略实现。 12345// 策略角色public interface Strategy &#123; // 算法方法 void algorithmInterface();&#125; 12345678910111213// 上下文角色public class Context &#123; Strategy strategy; public Context(Strategy strategy) &#123; this.strategy = strategy; &#125; //上下文接口 public void contextInterface() &#123; strategy.algorithmInterface(); &#125;&#125; 1234567// 具体的策略实现public class ConcreteStrategyA implements Strategy &#123; @Override public void algorithmInterface() &#123; System.out.println("算法A实现"); &#125;&#125; 具体实例假设某公司一款产品，针对不同的客户报价不同。 123456/** * 产品策略 */public interface ProductStragety &#123; double sell(double money);&#125; 1234567891011121314/** * 产品上下文 */public class ProductContext &#123; private ProductStragety stragety; public ProductContext(ProductStragety stragety) &#123; this.stragety = stragety; &#125; public double sell(double money)&#123; return stragety.sell(money); &#125;&#125; 12345678public class NormalCustomer implements ProductStragety &#123; @Override public double sell(double money) &#123; System.out.println("普通用户/新用户，原价出售"); return money; &#125;&#125; 12345678public class OldCustomer implements ProductStragety &#123; @Override public double sell(double money) &#123; System.out.println("老用户，95折"); return money*0.95; &#125;&#125; 1234567public class LargeCustomer implements ProductStragety &#123; @Override public double sell(double money) &#123; System.out.println("大用户，9折"); return money*0.9; &#125;&#125; 测试 12345678910111213141516public static void main(String[] args) &#123; ProductContext context1 = new ProductContext(new NormalCustomer()); ProductContext context2 = new ProductContext(new OldCustomer()); ProductContext context3 = new ProductContext(new LargeCustomer()); System.out.println(context1.sell(1000)); System.out.println(context2.sell(1000)); System.out.println(context3.sell(1000)); &#125; ----------------------------------------- 输出： 普通用户/新用户，原价出售 1000.0 老用户，95折 950.0 大用户，9折 900.0 应用场景JDK的Comparator就是使用了策略模式 123public static &lt;T&gt; void sort(List&lt;T&gt; list, Comparator&lt;? super T&gt; c) &#123; list.sort(c); &#125; 举例 1234567891011121314151617181920212223242526272829303132333435 public static void main(String[] args) &#123; List&lt;Person&gt; list = Lists.newArrayList(); list.add(new Person("d",30)); list.add(new Person("c",24)); list.add(new Person("b",25)); list.add(new Person("a",18)); System.out.println(list); Collections.sort(list,new PersonSortByName());-- System.out.println(list); Collections.sort(list,new ersonSortByAge());-- System.out.println(list); &#125; // 自定义比较策略 static class PersonSortByName implements Comparator&lt;Person&gt; &#123; @Override public int compare(Person o1, Person o2) &#123; return o1.getName().compareTo(o2.getName()); &#125; &#125; // 自定义比较策略 static class ersonSortByAge implements Comparator&lt;Person&gt; &#123; @Override public int compare(Person o1, Person o2) &#123; return o1.getAge().compareTo(o2.getAge()); &#125; &#125;------------------------------------------------------- 输出 [Person&#123;name='d', age=30&#125;, Person&#123;name='c', age=24&#125;, Person&#123;name='b', age=25&#125;, Person&#123;name='a', age=18&#125;] [Person&#123;name='a', age=18&#125;, Person&#123;name='b', age=25&#125;, Person&#123;name='c', age=24&#125;, Person&#123;name='d', age=30&#125;] [Person&#123;name='a', age=18&#125;, Person&#123;name='c', age=24&#125;, Person&#123;name='b', age=25&#125;, Person&#123;name='d', age=30&#125;]]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分库分表]]></title>
    <url>%2F2020%2F09%2F19%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[为什么需要分库分表？数据库数据会随着业务的发展而不断增多，单表单库性能就存在很大的问题了，如增删改查的开销也会越来越大。当一张单表的容量低于1千万以下是可接受的，这时B+Tree索引树高在3～5之间。 数据库瓶颈IO瓶颈第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询都会产生大量的IO，降低查询速度。（分库和垂直分表）第二种：网络IO瓶颈，请求的数据太多，网络宽带不够。（分库） CPU瓶颈第一种：SQL问题，如SQL中包含join、group by、非索引字段条件等,增加CPU运算等操作(SQL优化,优化索引)第二种：单表数据量太大，查询时扫描等行太多，SQL效率太多，CPU率先出现瓶颈（水平分表） 分库分表垂直分库说明根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务进行独立划分。项目一开始是一个单体应用，所有表数据都放在一个数据库里。之后随着业务增大，根据业务拆分成多个数据库。 特点每个库的结构都不一样.每个库的数据都不一样，没有交集。所有库数据的交集就是全量数据。 示例图 垂直分表说明把一张表的多个字段分别拆分成多个表，一般按字段的冷热拆分，热字段一个表，冷字段一个表。也可以叫主表和葱表,从而提升数据库性能. 特点每个表的结构不一样。每个表的数据也不一样。一般每个表至少有一列交集，一般是主键，用于关联数据。所有表的数据就是全量数据。 示例图 如上将商品的详情数据(冷数据)和基本信息(热数据)拆分成两张表。 水平分库说明以字段为依据，根据一定策略（hash、rangde等），将一个库中的数据拆分到多个库中。 特点每个库的结构都一样。每个库的数据都不一样。所有库的数据时候全量数据。 示例图 水平分表说明以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。一般单表数据超过1千万就要考虑水平分表了。 特点每个表的结构都一样。每个表的数据都不一样。所有表的并集是全量数据。 示例图 数据分片规则Hash取模分表一般采用Hash取模的切分方式，例如：假设按goods_id分4张表。（goods_id%4 取整确定表） 数值Range分表按照时间区间或ID区间来切分。例如：将goods_id为11000的记录分到第一个表，10012000的分到第二个表，以此类推。 工具及方案1.sharding-sphere：jar，前身是sharding-jdbc.2.TDDL：jar，Taobao Distribute Data Layer.3.Mycat：中间件. 总结这里总结的只是一些基础概念的东西，还需要结合实际操作增加认识与扩展。之后小编刚好会有一个实战项目，水平分表的实战，之后会结合总结的。 详细参考文章：https://juejin.im/post/6844903863464493064https://www.cnblogs.com/qdhxhz/p/11608222.html]]></content>
      <categories>
        <category>Java开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂方法模式]]></title>
    <url>%2F2020%2F09%2F04%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[简单工厂在工厂方法模式之前，先了解简单工厂.首先简单工厂不是一个标准的设计模式！简单工厂不是一个标准的设计模式！简单工厂不是一个标准的设计模式！简单的本质就是选择实现。工厂就是用来创建对象的，根据传入的参数，返回对应的实例对象。优点：帮助封装、解耦。缺点：不符合开闭原则，有新对象就要修改工厂类的代码. 1234567// 下面分别是小米手机类、华为手机类和苹果手机类// 1.正常创建使用// 我们创建它们的时候需要一个一个对象去newMiPhone mi = new MiPhone();IPhone i = new IPhone();HwPhone i = new HWPhone();// todo... 12345678910111213141516171819202122232425// 2.使用简单工厂// 都实现同一个接口或继承同一个对象PhoneHWPhone implements Phone IPhone implements Phone MiPhone implements Phone // 手机工厂类public class PhoneFactory &#123; public static Phone makePhone(String type) throws Exception &#123; if ("Mi".equals(type)) &#123; return new MiPhone(); &#125; else if ("I".equals(type)) &#123; return new IPhone(); &#125; else if ("HW".equals(type)) &#123; return new HWPhone(); &#125;else &#123; throw new Exception("没有该类型产品 type=" + type); &#125; &#125;&#125;// 获取Phone mi = PhoneFactory.makePhone("Mi");Phone i = PhoneFactory.makePhone("I");Phone hw = PhoneFactory.makePhone("HW");// todo... 总结简单工厂就是把对象全部向一个工厂里创建,根据类型参数返回不同的实力对象.优点：封装、实现客户端和具体实现类的解耦.缺点：不符合开闭原则，每次需要添加新的产品对象使都要修改工厂类. 工厂方法模式定义定义一个用于创建对象的接口,让子类决定实例化哪个类，工厂方法使一个类的实例化延迟到其子类。 结构 Creator:抽象工厂角色，是工厂方法模式的核心，与应用程序无关。ConcreteCreator：具体的工厂，Product方法的具体实现。Product：抽象产品角色，声明工厂方法，通常会返回一个Product类型的实例对象ConcreteProduct：具体的产品对象，实现抽象产品的所有方法。 具体示例代码1.定义一个抽象工厂 123public interface AbstractFactory &#123; Phone mackPhone();&#125; 2.产品各自的工厂实现这个抽象工厂,重写工厂方法，可以看到各自的工厂生产各自的产品 123456789101112131415161718192021// 苹果手机工厂public class IFactory implements AbstractFactory &#123; @Override public Phone mackPhone() &#123; return new IPhone(); &#125;&#125;// 小米手机工厂public class MIFactory implements AbstractFactory &#123; @Override public Phone mackPhone() &#123; return new MiPhone(); &#125;&#125;// 华为手机工厂public class HWFactory implements AbstractFactory &#123; @Override public Phone mackPhone() &#123; return new HWPhone(); &#125;&#125; 3.客户端使用 12345678910public static void main(String[] args) &#123; MIFactory miFactory = new MIFactory(); miFactory.mackPhone(); IFactory iFactory = new IFactory(); iFactory.mackPhone(); // 新增一个类型产品，只需添加新工厂，不要修改原有工厂 HWFactory hwFactory = new HWFactory(); hwFactory.mackPhone(); &#125; 总结相比较于简单工厂，工厂方法模式就是将工厂抽象化，将具体的产品分布在不同的具体工厂中操作,而且复合开闭原则，新的产品只要再写一个新的工厂就行，不用修改原来的工厂类。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式-构建者模式]]></title>
    <url>%2F2020%2F08%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%9E%84%E5%BB%BA%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[定义将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 结构与说明 Builder: 构建者接口，定义创建一个Product对象所需的各个部件的操作。ConcreteBuilder:具体的构建器实现，实现各个部件的创建，并负责组装Product对象的各个部件，同时还提供一个让用户获取组装完成后的产品对象的方法。Director:指导者，主要用来使用Builder接口，以一个统一的过程来构建所需要的Product对象。Product: 产品，表示被构建器构建的复杂对象。 使用场景现在有这样一个Hero类需要构造 1234567891011121314151617181920public class Hero&#123; // 代号(必须) private String code; // 姓名(必须) private String name; // 年龄(必须) private Integer age; // 主技能(必须) private String skillMain; // 技能1（可选） private String skill1; // 技能2（可选） private String skill2; // 技能3（可选） private String skill3; // 技能4（可选） private String skill4; ... &#125; 第一种：折叠构造函数模式通过传参构造需要的对象 123456789101112131415161718192021222324public Hero(String code, String name, Integer age, String skillMain) &#123; this.code = code; this.name = name; this.age = age; this.skillMain = skillMain; &#125; public Hero(String code, String name, Integer age, String skillMain, String skill1) &#123; this.code = code; this.name = name; this.age = age; this.skillMain = skillMain; this.skill1 = skill1; &#125; public Hero(String code, String name, Integer age, String skillMain, String skill1, String skill2) &#123; this.code = code; this.name = name; this.age = age; this.skillMain = skillMain; this.skill1 = skill1; this.skill2 = skill2; &#125;... 第二种：JavaBean模式创建一个对象,对其中的成员属性依次set(),get() 123456789101112131415161718192021// 无参构造方法public Hero() &#123; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; ... 从上述两种方法可以看出，当一个类对象非常复杂时，以上方法都有缺点第一种方式：代码阅读以及使用不方便,每次使用需要知道调用哪种构造方法，当参数很多时还需要注意参数顺序，易出错。第二种方式：在构建的过程中对象的状态容易发生变化，造成错误。针对以上问题，所以才有了Builder模式。当一个类对象非常复杂，构造的参数很多，并且这些参数是可选的，可以考虑使用构建者。 实现1.在Hero类中创建一个静态内部类Builder，参数和Hero类一样。(必要的参数用final修饰)2.将Hero的构造方法私有，且入参为Builder类，防止外部创建。只能由外部调用Builder类创建，所以也要在Builder里提供一个方法，返回Hero对象。3.Hero类的参数提供get()方法，Builder类的参数提供set()方法，返回值都为Builder对象，形成链式编程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class Hero &#123; /** * 姓名(必须) */ private final String name; /** * 主技能(必须) */ private final String skillMain; /** * 技能1（可选） */ private String skill1; /** * 技能2（可选） */ private String skill2; /** * 私有化Hero构造方法，外部只能通过Builder获取 */ private Hero(Builder builder) &#123; this.name = builder.name; this.skillMain = builder.skillMain; this.skill1 = builder.skill1; this.skill2 = builder.skill2; &#125; /** * 提供获取成员变量的方法 */ public String getName() &#123; return name; &#125; public String getSkillMain() &#123; return skillMain; &#125; public String getSkill1() &#123; return skill1; &#125; public String getSkill2() &#123; return skill2; &#125; @Override public String toString() &#123; return "Hero&#123;" + "name='" + name + '\'' + ", skillMain='" + skillMain + '\'' + ", skill1='" + skill1 + '\'' + ", skill2='" + skill2 + '\'' + '&#125;'; &#125; public static class Builder &#123; // 姓名(必须) private final String name; // 主技能(必须) private final String skillMain; // 技能1（可选） private String skill1; // 技能2（可选） private String skill2; /** * final修饰的参数为必传 */ public Builder(String name, String skillMain) &#123; this.name = name; this.skillMain = skillMain; &#125; /** * 设置成员参数，返回builder对象，链式编程 * * @param skill1 */ public Builder setSkill1(String skill1) &#123; this.skill1 = skill1; return this; &#125; public Builder setSkill2(String skill2) &#123; this.skill2 = skill2; return this; &#125; // 提供一个返回Hero的方法 public Hero builder() &#123; return new Hero(this); &#125; &#125;&#125; 测试结果： 123456789public class Test &#123; public static void main(String[] args) &#123; Hero.Builder builder = new Hero.Builder("萧峰", "降龙十八掌"); Hero hero = builder.setSkill1("打狗棒法").setSkill2("少林武学").builder(); System.out.println(hero); &#125;&#125;-------------------------------------------------------------------Hero&#123;name='萧峰', skillMain='降龙十八掌', skill1='打狗棒法', skill2='少林武学'&#125; 总结可以看出，本文只是用了传统构建者模式的变种。这也是平时项目开发中遇到常用的方式了，继续练习～]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[类加载器和双亲委派机制]]></title>
    <url>%2F2020%2F08%2F22%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E4%B8%8E%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[类的加载过程加载在硬盘上查找通过I/O读取字节码文件,生成类的二进制数据（.class文件） 验证校验生成的字节码文件的正确性 准备给类的静态变量分配内存,并赋予默认值 解析符号引用转化为直接引用 初始化对类的静态变量初始化为指定的值,执行静态代码块 注：类被加载到方法区中主要包含 运行时常量、类型信息、字段信息、方法信息、类加载器的引用（这个类到类加载器实例等引用）、对应classs实例的引用（类加载器在加载类信息放到方法区后，会创建一个对应的class类型的对象放到堆中）等信息.还有主类运行过程中，如果使用到其他类，会逐步加载这些类。jar包和war包里的类都是懒加载。 类加载器引导类加载器(BootStrapClassLoader)负责加载支撑JVM运行的位于JRE的lib目录下的核心类库,比如rt.jar、charsets.jar等 扩展类加载器(ExtClassLoader)负责加载支撑JVM运行的位于JRE的lib目录下的ext扩展目录中的jar类包 应用程序加载器(AppClassLoader)负载加载ClassPath路径下的类包,主要加载你自己写的那些类 自定义类加载器负责加载用户自定义路径下的类包 如下代码分别输出BootStrapClassLoader、ExtClassLoader、AppClassLoader.由于引导类加载器是C语言写的所以返回null。 123456System.out.println(String.class.getClassLoader()); System.out.println(com.sun.crypto.provider.DESKeyFactory.class.getClassLoader().getClass().getName());System.out.println(TestJDKClassLoader.class.getClassLoader().getClass().getName());--------------------------------------------nullsun.misc.Launcher$ExtClassLoadersun.misc.Launcher$AppClassLoader 类加载器之间关系 1234567891011 ClassLoader appClassLoader = ClassLoader.getSystemClassLoader(); ClassLoader extClassloader = appClassLoader.getParent(); ClassLoader bootstrapLoader = extClassloader.getParent();System.out.println("the bootstrapLoader : " + bootstrapLoader);System.out.println("the extClassloader : " + extClassloader);System.out.println("the appClassLoader : " + appClassLoader);---------------------------------------------------------the bootstrapLoader : nullthe extClassloader : sun.misc.Launcher$ExtClassLoader@776ec8dfthe appClassLoader : sun.misc.Launcher$AppClassLoader@18b4aac2 如上代码可以看出JVM类加载器是有亲子层级结构的BootStrapClassLoader -&gt; ExtClassLoader -&gt; AppClassLoader -&gt; 自定义类加载器 双亲委派机制 如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给自己的父类去完成，一次向上。只有当父类无法完成该加载时，子加载器才会尝试自己去加载该类。这就是类加载的双亲委派机制：先找父亲加载，不行再由儿子自己加载 举例假设现在要加载Math类，最先会找AppClassLoader加载，AppClassLoader会委托ExtClassLoader加载，ExtClassLoader则又会委托BootStrapClassLoader加载，BootStrapClassLoader是顶层引导类加载器，则会在自己的类加载路径里找Math类，没有则退回BootStrapClassLoader，BootStrapClassLoader则会在自己的类加载路径里找Math类，也没有则最后退回到AppClassLoader类加载，最终在AppClassLoader的加载路径里找到Math类，最后就自己加载了。 为什么要设计双亲委派机制？沙箱安全机制这样可以防止核心类被篡改,比如rt.jar里有一个常用的java.lang.String.class类，这样你自己写的相同路径的java.lang.String.class类就不会被加载。 避免类的重复加载当父亲已经加载过的类路径，子类就没有必要再去加载一次,保证被加载类的唯一性。 全盘委托机制如果一个类加载，这个类依赖的其他类，也会一起加载。 自定义类加载器自定义类加载器需要继承 java.lang.ClassLoader 类,这个类有两个核心方法，loadClass(String, boolean)，实现了双亲委派机制。findClass，默认实现是空方法，所以我们自定义类加载器主要是重写findClass方法。自定义类加载器默认父加载器是AppClassLoader。 123456789101112131415161718192021222324public Class&lt;?&gt; loadClass(String var1, boolean var2) throws ClassNotFoundException &#123; int var3 = var1.lastIndexOf(46); if (var3 != -1) &#123; SecurityManager var4 = System.getSecurityManager(); if (var4 != null) &#123; var4.checkPackageAccess(var1.substring(0, var3)); &#125; &#125; if (this.ucp.knownToNotExist(var1)) &#123; Class var5 = this.findLoadedClass(var1); if (var5 != null) &#123; if (var2) &#123; this.resolveClass(var5); &#125; return var5; &#125; else &#123; throw new ClassNotFoundException(var1); &#125; &#125; else &#123; return super.loadClass(var1, var2); &#125; &#125; 1234567891011121314151617181920212223242526272829protected Class&lt;?&gt; findClass(final String name) throws ClassNotFoundException &#123; final Class&lt;?&gt; result; try &#123; result = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;() &#123; public Class&lt;?&gt; run() throws ClassNotFoundException &#123; String path = name.replace('.', '/').concat(".class"); Resource res = ucp.getResource(path, false); if (res != null) &#123; try &#123; return defineClass(name, res); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name, e); &#125; &#125; else &#123; return null; &#125; &#125; &#125;, acc); &#125; catch (java.security.PrivilegedActionException pae) &#123; throw (ClassNotFoundException) pae.getException(); &#125; if (result == null) &#123; throw new ClassNotFoundException(name); &#125; return result; &#125;]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Syncronized关键字]]></title>
    <url>%2F2020%2F08%2F15%2FSynchronized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[概念Syncronized是JVM自带的关键字，主要用来解决线程并的原子性问题。Syncronized保证多个线程并发，在同一时刻只能有一个线程访问临界资源。在多线程可能出现同时访问一个共享、可变资源的情况，这个资源叫临界资源（对象、变量、文件等）。 用法静态方法：类锁,锁得是当前类的class对象普通方法：对象锁,锁得是当前实例对象同步代码块：锁得是括号里的对象 注：一个类只有一个class,可能有多个实例对象. 若一个类有多个静态方法，可能会造成性能影响。 锁升级历史Synchronized在JDK1.6之前性能非常的低，使用的时候需要用户态与内核态的切换。所以Doug li 写了AQS框架，实现了ReentranLock(java语言写的)，性能远远高于JVM自带的Syncronized。之后甲骨文收购了java,觉得Syncronized干不过ReentranLock，为了颜面，在JDK1.6之后对Syncronized进行了优化，即锁的升级，目前Syncronized和ReentranLock的性能五五开。 升级过程锁得状态一共四种：无锁状态、偏向锁、轻量级锁、重量级锁。无锁状态当没有线程访问被syncronized修饰得方法或代码块时，就是无锁状态. 偏向锁当第一个线程访问syncronized修饰的方法或代码块时,锁就进入了偏向模式,此时JAVA对象头里的Mark Word的结构也变为偏向锁结构.当其他线程请求锁的时候，会CAS替换JAVA对象头里的Mark Word里偏向锁的信息，替换成功就获取到锁资源。记录在Mark Word的里的线程再次请求锁资源，不需要做任何同步操作，省去大量锁申请操作，也就提升了性能。 轻量级锁对于锁竞争激烈的场景，偏向锁就失效了。但是JVM并不会立刻升级为重量级锁,会先将Mark Word的结构变为轻量级锁的结构。轻量级锁适应的场景是线程交替执行代码块的场合，如果存在同一时间访问同一锁的场景，就会升级为重量级锁。 重量级锁在轻量级锁失败后，jvm会先进行自选锁的操作。会先让当前想获取锁的线程做空循环,经过一定次数的循环，如果还得不到锁，就只能升级为重量级锁。 注：锁得升级是不可逆的～ 加锁信息锁信息展示（32位虚拟机）]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字]]></title>
    <url>%2F2020%2F08%2F15%2FVolatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[概念volatile是Java虚拟机提供的轻量级的同步机制。volatile能保证并发编程的两个问题：可见性和有序性。 可见性 问题：从JMM模型可以知道，线程都是从总内存中加载变量到自己的工作内存，所以在多线程情况下，线程A获取了主内存的共享变量X，线程B也获取了变量X，并且将它修改。这时线程A无法立刻知道自己工作内存里的变量X与主线内存的变量X已经不同。 解决：使用volatile修饰共享变量. 缓存一致性原则MESIM 已修改状态 （加锁成功）E 独占状态 （一个cpu读到）S 共享状态（多个cpu读到）I 失效状态 （收到其他cpu的消息）当其他线程把主内存的值修改后，工作内存的缓存就被消除掉了。底层就是volatile 调用一个lock指令，修改值经过总线的时候会触发缓存一致性协议，将其他工作内存对应的缓存值变为失效状态，其他线程需要读取值需要重新去主内存读取。 防指令重排 12345678910111213public LazySingleton getInstance3() &#123; if (instance == null) &#123; // 实例化对象 加锁 synchronized(LazySingleton.class) &#123; if(instance == null) &#123; instance = new LazySingleton(); &#125; &#125; &#125; // 返回对象 return instance; &#125; 问题:上图是单例模式double check，LazySingleton的实例化需要经过分配空间 -&gt; 初始化 -&gt; 引用赋值,但是JVM底层可能会对其指令重排为分配空间 -&gt; 引用赋值 -&gt; 初始化，这样返回的instance可能只是赋值而未初始化，可能有npe问题。 解决：使用volatile修饰该实例对象. 内存屏障内存屏障，又称内存栅栏，是一个CPU指令，它的作用有两个，一是保证特定操作的执行顺序，二是保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）。由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。 总之，volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JMM模型]]></title>
    <url>%2F2020%2F08%2F08%2FJMM%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[什么是JMM模型？JMM模型就是Java内存模型，是一种抽象的概念,并不真实存在。它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（实例字段、静态字段、构成数组对象的元素）的访问方式。JVM运行程序的实体是线程，每当创建线程时JVM都会为其创建一个工作内存,每个线程都有自己独有的工作内存存储私有数据，但是JMM规定所有的变量都存储在主内存，主内存是共享区域，所有线程都可以访问，但是对变量的操作需要在各自的工作内存中操作，操作完后写回主内存,不能直接操作主内存中的变量。 数据同步八大原子操作关于主内存和工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存，如何从工作内存同步到主内存之间的实现,JMM定义了以下8种操作完成。lock(锁定)作用与主内存的变量，把一个变量标记为一条线程独占状态。unlock(解锁)作用与主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。read(读取)将主内存的数据拷贝一份，便于随后的load使用load(载入)将read拷贝的数据加载到工作内存中use(使用)将工作内存中的数据变量给执行引擎进行逻辑修改assign(赋值)将执行引擎修改的值写回线程的工作内存store(存储)将工作内存的值拷贝一份出来write(写入)将store出来的值写回主内存 举例：假设线程A要修改主内存中的变量a = 0 -&gt; a=1首先read将主内存的变量a=0拷贝一份，通过load加载到线程A的工作内存,然后use将工作内存中a=0交给执行引擎，执行引擎将a=0修改为a=1，assign将a=1写回工作内存，store将工作内存中的a=1拷贝一份出来，write将a=1写回主内存。 并发编程三大特性原子性原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。通常使用 synchronized、Lock （ volatile不保证原子性） 可见性当一个线程修改了某个共享变量 的值，其他线程是否能够马上得知这个修改的值。volatile可以解决可见性（保证能否及时看到）。 有序性 有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，但对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象，重排后的指令与原指令的顺序未必一致。volatile可以防止指令重排。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MVCC机制]]></title>
    <url>%2F2020%2F08%2F01%2FMVCC%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MVCC概述Mysql在可重复读隔离级别下，同样的sql查询语句在一个事务里多次执行查询结果是相同的，就算其他事物对数据有修改也不会影响当前事物sql语句的查询结果。这个隔离性就是靠MVCC（多版本并发控制）机制保证的，对一行数据的读和写两个操作默认不会通过加锁互斥来保证隔离性，避免了 频繁加锁。 MVCC机制的实现undo日志undo日志版本链是指一行数据被多个事务依次修改后，在每个事务修改完后，mysql会保留修改之前的数据在undo日志，并且用两个隐藏字段trx_id(事务id)和rollpoint（指针）把这些日志记录连接起来，形成一个历史记录版本链。如下图 红色代表id=1的这行历史修改记录，蓝色代表最新数据。undo日志只有一份。 Read-view 一致性视图每个事务开启都会维护一份自己的一致性视图。视图组成执行查询时所有未提交事务的id数组 + 已创建的最大事务id组成 视图生成时机可重复读隔离级别，在第一次查询就会生成Read view。读已提交隔离级别， 每次读都会生成一份最新的Read view 版本对比举例事务里的任何sql查询结果需要从对应的版本链的最新数据开始逐条做对比得到最终的结果。拿上图数据举例：假设事务A的视图为[200] 300，去查询id=1的数据 首先找到蓝色最新的数据,事务id是200,200在事务A的一致性视图中是属于未提交的，所以数据 不可见，再找下一条事务id也是200,还是不可见，逐一比对，到事务id=100时，100不在事务A 的一致性视图里，说明是已提交的事务，所以最终得到的值就是’lilei2’。 版本链对比规则 如果undo日志里的数据行trx_id(事务id)落在绿色部分，说明这个版本是已提交的事务生成的，所以数据可见。如果undo日志里的数据行trx_id(事务id)落在红色部分，说明这个版本是由将来启动的事务生成，肯定不可见。如果undo日志里的数据行trx_id(事务id)落在黄色部分，就需要判断了 a.trx_id在视图数组里，说明这个版本是由还没提交的事务生成的，数据不可见。 b.trx_id不在视图数组里,说明这个版本是已经提交的事务生成的,数据可见。 总结MVCC机制的实现就是通过read-view机制与undo版本链对比机制，使得不同的事务会根据数据版本链对比规则读取同一条数据在版本链上不同版本的数据。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql事务隔离级别与锁机制]]></title>
    <url>%2F2020%2F08%2F01%2FMysql%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8E%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[为什么要事务隔离与锁机制？数据库一般都会并发执行多个事务，多个事务间可能会并发对相同的一批数据进行增删改查操作，就可能会造成一些事务隔离性问题，例如：脏写、脏读、不可重复读、幻读。 事务及其ACID属性事务是由一组SQL语句组成的逻辑处理单元,具有以下4个属性,简称事务的ACID属性。原子性执行事务操作，一系列对数据修改的操作，这些操作要么全部执行成功，要么全部失败。一致性事务开始到结束，数据必须保持一致性。举例：银行转账操作，两个账户转钱。账户的总金额不会改变。隔离性多个事务之间相互隔离，互相不打扰。（这里可能有许多隔离性问题）永久性事务结束后，数据的修改会永久的保存在数据库里。 事务隔离性问题脏写假设同时开启事务A,B,选择数据表中同一行数据进行修改，A事务先完成了对数据的修改并提交了事务，之后B事务对同一数据也修改提交。最终数据库里的数据是事务B修改的数据。覆盖了A之前修改的数据。就造成了脏写。 脏读两个事务A,B，事务B读到了事务A已经修改但是还没有提交的数据。事务A对数据行进行了修改，但是还没有提交事务。这时事务B读到了A事务还没有提交的事务，还用这个数据去操作。如果A事务回滚了，那这个数据就是无效的。不符合一致性要求。 不可重复读线程AB开启事务，A,B同时读到一行数据，A更新了这条数据，并提交了事务，B还未提交事务，重新去读这行数据，导致B一次事务里两次读到的数据不相同。 幻读幻读类似不可重复读;不可重复读针对查询操作;幻读针对读是插入和删除操作。 事务隔离级别针对以上问题，Mysql数据库提供了一定的事务隔离级别机制来解决。 Mysql数据库默认的隔离级别是可重复读。 查看当前数据库的事务隔离级别: show variables like ‘tx_isolation’; 设置事务隔离级别：set tx_isolation=’REPEATABLE-READ’; MySql锁机制锁详解锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除了传统的计算资源（CPU、RAM、I/O等）竞争外，数据也是一种共享等资源。 锁分类123456从性能上分乐观锁用版本号对比来实现，每次修改数据的时候会先比较读到数据的版本号和最新的版本号是否一致，一致就可以修改，否则不行。乐观锁实际上是不加锁的。悲观锁对数据进行加锁，访问资源需要竞争锁。 12345678从对数据库操作的类型分分为读锁写锁，都是悲观锁。**读锁会阻塞写，写锁会阻塞读和写。读锁读锁也称共享锁，S锁（share），针对同一份数据，多个读操作可以进行而不会相互影响。写锁写锁也称排他锁，X锁（eXclusive），针对同一份数据，写操作没有完成，其他事物的读/写都会堵塞。 12345678从对数据操作的粒度分MyISAM是表锁。InnoDB查询的时候有mvcc机制不会加锁，但是更新、插入、删除操作会加行锁。表锁每次操作都会锁住整张表。找到表就可以加锁，开销小，加锁快。锁的粒度大，不会出现死锁。发生锁冲突的概率最高，**一般用在整表数据的迁移**。行锁每次操作锁住操作涉及到的数据行。需要找到对应的数据行才能加锁，开销大，加锁慢。锁的粒度小，会出现死锁。 锁和事务隔离级别隔离级别设置​ 读未提交 set tx_isolation=’read-uncommitted’;​ 读已提交 set tx_isolation=’read-committed’;​ 可重复读 set tx_isolation=’repeatable-read’;​ 串行化 set tx_isolation=’serializable’; 锁和事务隔离级别可重复读就是假设某一事务对数据行就行了更新操作就会对涉及到的数据行加行锁。序列化只要开启了事务，之后的操作，不管查询操作还是更新操作，对涉及到的数据行全部加行锁，所以性能差。间隙锁因为mysql的默认隔离级别是可重复读，会有幻读的问题。可以引入间隙锁在某些情况下可以解决该问题。 如上表所示间隙就有id为 （3，10）、(10,20)、(20,正无穷)防止幻读就是需要被涉及的数据行加锁update account set name = ‘萧峰666’ where id &gt; 8 and id &lt;18;上述sql会对id值有在（3，10）区间的，也有在（10，20）区间的，所以最终被锁定的区间是（3，20],其他事务没法在这区间插入或修改任何数据。间隙锁只在可重复读隔离级别下才生效。 锁优化 尽可能让所有数据检索都通过索引完成，避免无索引行锁升级为表锁。 合理设计索引，减小锁的范围。 尽可能减小检索条件范围，避免间隙锁。 尽量控制事务大小，减小锁定资源量和时间长度，涉及事务加锁的sql放在事务最后执行。 尽可能低级别事务隔离]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SQL优化]]></title>
    <url>%2F2020%2F07%2F20%2FSQL%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[开发过程中,经常会碰到一些慢sql，性能低，执行时间太长、等待时间太长、sql语句欠佳、索引失效、服务器参数设置不合理需要我们对sql进行适当的优化，所以需要了解如何去优化哈.下面整理了一些mysql的sql结构以及该如何去优化sql。 mysql的逻辑分层原理 连接层 提供与客户端连接的服务 服务层 提供各种用户使用的接口（增删改查）,提供sql优化器 引擎层 提供各种存储数据的方式，例如默认的InnoDB（事务优先，行锁）、MyISAM(效率优先，表锁)等 存储层 存储最终的数据 sql 编写过程select…from…join…on…where…group by…having…order by…limit..sql 解析过程from…on..join…where…group by…having..select…order by…limit.. 核心是优化索引索引定义帮助mysql高效获取数据的数据结构，索引是数据结构. 索引分类​ 主键索引：与唯一基本相同（主键不能为null，唯一可以为null）​ 单值索引：单列（一个表可以有多个单值索引） 唯一索引：不能重复（例如id） 复合索引：多个列构成的索引s 索引优势提高查询效率（降低IO的使用率)降低CPU使用率（索引是排好序的结构，可以直接用） 索引弊端索引本身很大，可以存放在内存/硬盘不是所有情况使用：a.少量数据 b.频繁更新的字段 c.很少使用的字段索引会提高查的效率，会降低增删改的效率 SQL性能问题分析SQL的执行计划：EXPLAIN+SQL12id: 编号id值相同，从上往下顺序执行(表的执行顺序会因为数量改变而改变，原因：笛卡尔积，数据小的表优先查询)，id值不同：越大越优先查询（在查询时先查内层再查外层） 123456select_type: 查询类型 PRIMARY:主查询 SUBQUERY:子查询 SIMPLE:简单查询（不包含主、子查询） DERIVER：衍生查询（使用到临时表,From后面的查询） UNION：在from子查询中table1 union table2（指的table2） 1table: 查询的表 123456789type: 索引类型 system-&gt;const-&gt;eq_ref-&gt;ref-&gt;range-&gt;index-&gt;all（越往左效率越高） Null:MySql底层会对查询进行优化,直接查询常量 system:查询得表里只有一条数据行 const:结果集只有一条数据 （通过主键索引和唯一索引查询） eq_ref:表关联用主键或唯一键 ref:表查询没有用到主键或唯一，但是用到了普通索引，可能返回匹配的多条数据或0条。（从索引的根节点开始找） range:检索指定范围的行，使用一个索引来选择行（between,&lt;,&gt;,=） index:扫描所有的索引（叶子结点全索引扫描），一般去扫二级索引，因为主键索引太大 all:全表读取 1possible_keys: 预测可能使用的索引 1key: 实际使用的索引 12345678910111213141516171819key_len:实际使用的索引的长度（作用：判断复合索引是否完全被使用） 字符串 char(n):3n字节长度 varchar(n):若是utf-8，长度为3n+2 (加的2是存储字符串长度的) 数值类型 thinyint:1字节 smallint:2字节 int:4字节 bigint:8字节 时间类型： date:3字节 timestamp:4字节 datetime:8字节 *如果字段允许为null，还需要加1个字节，记录是否为NULL。*例如：联合索引 name age address name varchar(20) 不为null age int 可为null address char(30) 可为null 则key_len = （20*3+2） + （4+1）+（30*3+1） = 158 1ref: 联合索引关联的字段（可能是个常量值const） 1const:常量 1rows:可能检测到的行数 1234567891011Extra:展示额外信息 性能从好到坏:using index &gt; using where &gt; using temporary | using filesortusing index: 索引覆盖，不读取原文件，只从索引文件中获取（不需要回表查询） （覆盖索引：使用联合索引查找没有回表查）using where: 需要回表查询(需要查询原文件)using filesort（性能损耗大）常见于order by，没有索引需要放在临时表里比较using temporary（性能损耗大，额外多使用临时表）常见于distinct 去重，没有索引需要放在临时表里比较 SQL优化器可能干扰我们的优化SQL的优化主要通过上述的属性去优化，但是SQL优化器可能会干扰我们的优化. 常用SQL优化方法123456789101112131415161718191.加索引 a.索引不能跨列，保持索引的定义和使用一致（根据sql实际解析的顺序，调整索引的顺序，从from开始节气解析）； b.索引要逐步优化 c.范围查询in可能使索引失效，放到where条件最后面2. 多表 a.小表驱动大表 b.索引建立在经常查询的字段 3. 避免索引失效的一些原则 a.复合索引，不要跨列或无序使用（最佳左前缀） b.复合索引，尽量使用全索引匹配 c.不要在索引上进行任何操作（计算，函数，类型转换），否则索引失效 d.复合索引不能使用不等于（!=，&lt;&gt;）或is null，否则索引失效 e.尽量使用索引覆盖（using index） f.like尽量已“常量”开头，不用以“%”开头，否则索引失效（如果必须使用，可以用索引覆盖补救一部分） g.尽量不要使用类型转换（显式，隐式），否则索引失效 h.尽量不要使用or，否则索引失效 注：双层循环：（外层小内层大）性能比（外层大内层小）好 MySql锁机制12345678解决因资源共享而造成的并发问题- 操作类型分： 1.读锁（共享锁）:对同一个数据，多个读操作可以同时进行（买衣服的看） 2.写锁（互斥锁）:如果当前操作没有完毕，则无法进行读写操作（买衣服一系列操作）- 操作范围分： 1.表锁：一次性对一张表整体加锁（myISAM存储引擎），开销小，加锁快，锁的范围大，无死锁，容易发生锁冲突 2.行锁：一次性对一行数据加锁（innoDB存储引擎），开销大，加锁慢，容易出现死锁，不易发生锁冲突 3.页锁]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql索引数据结构]]></title>
    <url>%2F2020%2F07%2F18%2FMysql%E7%B4%A2%E5%BC%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[什么是索引？索引是帮助Mysql高效获取排好序的数据结构。 磁盘IO数据库的数据都是存放在本地磁盘里的，每次查询数据都会进行磁盘IO读取数据，将读到的数据加载到内存中比较，Mysql InnoDB默认一次磁盘IO的大小是16K. 调用以下命令查询 SHOW GLOBAL STATUS like &#39;Innodb_page_size&#39;; 索引数据结构二叉树首先看下图 假设需要根据字段col2查询col2=22的数据，select * from table where col2 = 22。 无索引全表查，从上至下 34 -&gt;77 -&gt;55 -&gt;91 -&gt;22 每一次的查询都会进行一次磁盘IO，可以看出上述操作一共进行了5次磁盘IO才找到了col2=22的数据行。 使用二叉树索引看上图右边的树，就是为上述col2字段建立的一个二叉树索引，我们都知道二叉树索引是大的元素放右边，小的元素放左边。 根据索引的查询22，首先会查询到34，判断22&lt;34就会去树的左边结点，再次查询就找到22了，所以上述查询采用索引只用了2次磁盘IO 注：二叉树存储的 key是索引值，value是该索引值对应的数据行地址。缺点根据二叉树结点存放的特点，如果给Col1字段建立二叉树索引，就是如下图所示，形成一个单项的链表结构，这样的查询和全表查询没有什么区别。 平衡二叉树（AVL）为了避免上述二叉树的缺点，进而引入了一种新的数据结构那就是平衡二叉树。 它有一个非常严格的要求：必须保证左右子树高度差不超过1. 它虽然避免了二叉树变成链表结构的尴尬，但是如果数据量非常非常大的情况下，树的层级就会非常的高，这样就会进行多次的磁盘IO,效率就会非常低下，所以AVL也不是Mysql InnoDB的索引结构。 BTreeBTree做了改进就是它每个结点不止一个元素,每个元素不重复，并且每个结点中的元素从左到右依次递增排序。每个结点都有索引和数据。 还是回到原来的问题，当数据量很大的时候，树的层级还是会很深，又会进行多次磁盘IO，效率就低下了。而且查询不稳定，可能第一次IO就查到数据了，也可能在最后一层叶子结点查询到数据。所以它也不是Mysql InnoDB的索引结构。 B+Tree 比较BTree 和B+Tree的结构图可以看出，B+Tree相较于BTree： 数据全都存放在叶子结点。这样可以保证每次磁盘IO读到的索引元素更多，降低树的高度，增加命中率。 还可以可以保证查询效率的稳定。 叶子结点之间有结点指针因为索引都是排好序的，这样可以适用于范围查询，提高效率。 假设下可以存储的索引数量一次IO是16K,假设索引是一个bigint(8B),上图空白格表示下一个磁盘地址（6B） 根节点第一次IO大概：16*1024/(8+6) = 1170 第二次IO:1170 叶子结点中有数据行：假设一行数据1KB，一次IO 16K所以可以放16 这棵树放满大约能放的索引是：1170 1170 16 = 21902400（2千多万） 综上：3层的B+Tree结构可以存放2千多万的索引数据;所以Mysql的InnoDB底层索引结构就是B+Tree. 一些高版本的mysql会将根节点直接加载到内存，查询到时候可以免去第一次磁盘IO.Hash结构 Hash结构底层是数组和链表 建立索引将索引的值进行hash运算，算出该元素所在的桶的位置，然后判断该位置是否有元素，没有就直接塞进去，有的话说明hash冲突，用链表连接。 查询数据查询数据的时候也先将值进行hash运算，找到具体的位置查找。类似于HashMap的底层原理吧。 综上：hash运算非常的开，所以hash结构查询效率非常快，但是它无法支持范围查询。聚集索引与非聚集索引 上述是一行一行的数据… 聚集索引 聚集索引：叶子结点包含数据的，索引和数据放在一起的。 聚集索引的确定（依次选择）：B+tree默认首先获取主键 -&gt; 不为null的唯一键列 -&gt; 默认生成一个id行 非聚集索引 非聚集索引：叶子结点不包含数据的，放的是主键的id。 这样做是为了节约存储空间；也保证一致性，数据行修改了不用两棵树都去修改。 InnoDB 表建立主键，主键通常都用整型且自增的原因用整型的原因：索引用整型比较大小快。 自增的原因：因为叶子结点都是排好序的，如果不自增，可能会导致树结构的自平衡，影响效率。 联合索引/复合索引为什么是最左前缀原理？首先看下联合索引的索引结构图 可以看到联合索引的顺序是：name、age、position 因为索引都是排好序的，按上面的结构，必须先找到name, 假设是Bill，在Bill的基础上，age是排好序的 不然人工直接找age，它就是没有顺序的 综上：联合索引是一级一级查询的，所以按最左前缀原理。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Idea 查看源码]]></title>
    <url>%2F2020%2F07%2F15%2FIdea%E5%A6%82%E4%BD%95%E7%9C%8B%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[描述平时开发代码，避开不了需要查看源码，例如JDK、spring的源码那都是精华，非常值我们去推敲学习的，但是在Idea直接点开下载源码是不能在上面做笔记的，所以希望看源码的时候可以把自己理解的内容写注释，方便下次观看立即能回忆起来。而且能够Debug调试。 方法就拿JDK的源码为例。1.找到JDK的zip包然后解压2.打开Idea的SKDs,在sourcepath配置解压好的jdk包3.最后就能在源码写注释了(以HashMap源码为例)]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2020%2F07%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式：保证一个类仅有一个实例，并提供一个全局访问它的全局访问点。应用场景: 线程池、数据库连接等。 单例实现实例单例模式主要分为两种：懒汉式和饿汉式。1.构造方法私有化。2.提供一个全局访问点. 饿汉式123456789101112131415public final class HungrySingleton &#123; // 自行创建实例 private static HungrySingleton instance = new HungrySingleton(); // 构造方法私有化 private HungrySingleton() &#123; &#125; // 通过该函数向整个系统提供获取方法 public HungrySingleton getInstance() &#123; return instance; &#125;&#125; 原理使用static修饰了成员变量instance,这样类初始化的过程中被收集进类构造器即“clinit”方法中，在多线程下JVM会保证只有一个线程会执行clinit方法，其他会阻塞等待。等到唯一的一次clinit方法执行完成，其他线程将不会再执行该方法，转而执行自己的代码。也就是说static修饰的成员变量instatnce只会被初始化一次。 优缺点优点：可以保证多线程情况下实例的唯一性，getInstatce方法直接返回实例，性能非常高。缺点：在类成员变量比较多活比较大的情况下，可能在没有使用类的时候一直占用着堆内存，造成内存的浪费。 懒汉式懒汉模式就是为了避免直接加载类对象造成堆内存浪费的一种单例模式。 情况一12345678910111213141516171819public final class LazySingleton &#123; // 不实例化 private LazySingleton instance = null; // 构造方法实例化 private LazySingleton() &#123; &#125; // 1.原始方法 // 这样虽然避免了类加载提前创建实例，但是在多线程运行下，就会出现多个实例创建的情况。 public LazySingleton getInstance() &#123; if (instance == null) &#123; // 实例化对象 -- 多个线程会创建多个对象 instance = new LazySingleton(); &#125; // 返回对象 return instance; &#125; 情况二123456789101112131415161718192021public final class LazySingleton &#123; // 不实例化 private LazySingleton instance = null; // 构造方法实例化 private LazySingleton() &#123; &#125; // 2.饿汉式 + synchronized // 这样虽然可以避免多线程问题，但是同步锁会增加锁竞争，每次获取实例对象都会通过getInstance方法，带来系统性能开销，导致系统性能下降。 public synchronized LazySingleton getInstance1() &#123; if (instance == null) &#123; // 实例化对象 instance = new LazySingleton(); &#125; // 返回对象 return instance; &#125; 情况三1234567891011121314151617181920212223public final class LazySingleton &#123; // 不实例化 private LazySingleton instance = null; // 构造方法实例化 private LazySingleton() &#123; &#125; // 3.饿汉式 + synchronized 减小锁的粒度 // 在创建实例对象的时候加同步锁，但是依然存在可能创建多个实例，因为在进入null判断的时候可能有多个线程 public LazySingleton getInstance2() &#123; if (instance == null) &#123; // 实例化对象 加锁 -- 这里可能多个线程等待，最终也会导致多个对象创建 synchronized(LazySingleton.class) &#123; instance = new LazySingleton(); &#125; &#125; // 返回对象 return instance; &#125; 情况四1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public final class LazySingleton &#123; // 不实例化 private volatile LazySingleton instance = null; // 构造方法实例化 private LazySingleton() &#123; &#125; // 4.饿汉式 + synchronized double check // 当线程拿到锁准备创建对象时，再判断一次实例是否已经创建。这种方法被称为Double-Check,它可以大大提高懒汉模式性能。 // 但是也不能保证万无一失。以防万一变量添加volatile 防止指令重排序。 // 创建一个对象底层字节码的执行顺序是1.分配空间 2.初始化 3. 引用赋值 -&gt; 指令重排后可能变为1.分配空间 2.引用赋值 3.初始化 当第一个线程引用赋值后，第二个线程进来发现instance不为null,就直接返回使用，但是这时instance可能还 没有初始化，所以可能会npe; public LazySingleton getInstance3() &#123; if (instance == null) &#123; // 实例化对象 加锁 synchronized(LazySingleton.class) &#123; if(instance == null) &#123; instance = new LazySingleton(); &#125; &#125; &#125; // 返回对象 return instance; &#125; /** * 通过内部类实现 * * @return */ // 4.通过内部类实现 // 通过饿汉式可以知道通关键字static修饰变量，在类初始化加载的时候只有一个线程可以执行clinit方法，其他会阻塞等待。 // 所以可以利用这个特性在Singleton类中创建一个内部类来实现。内部类的静态成员变量是懒加载，并且内部类可以调外部类的私有构造方法。 public static class InnerSingleton &#123; private static LazySingleton instance = new LazySingleton(); &#125; public LazySingleton getInstance4() &#123; return InnerSingleton.instance; &#125; // 5.枚举类(核心就是内部类) 情况五123456789101112131415161718public final class LazySingleton &#123; // 不实例化 private volatile LazySingleton instance = null; // 构造方法实例化 private LazySingleton() &#123; &#125; // 5.通过内部类实现 // 通过饿汉式可以知道通关键字static修饰变量，在类初始化加载的时候只有一个线程可以执行clinit方法，其他会阻塞等待。 // 所以可以利用这个特性在Singleton类中创建一个内部类来实现。内部类的静态成员变量是懒加载，并且内部类可以调外部类的私有构造方法。 public static class InnerSingleton &#123; private static LazySingleton instance = new LazySingleton(); &#125; public LazySingleton getInstance4() &#123; return InnerSingleton.instance; &#125; 情况六枚举类(核心就是内部类) 总结其实单例模式的本质就是控制对象实例的个数。懒汉式和饿汉式各有各的优缺点，可以适当根据应用场景使用。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Idea永久破解]]></title>
    <url>%2F2020%2F07%2F15%2FIdea%E6%B0%B8%E4%B9%85%E7%A0%B4%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[描述最近刚好换了工作，要换台电脑工作了，安装了Idea,忘记了原来Idea破解的方法，于是网上查找，果然好记性不如烂笔头，决定总结一下，记录下来。就是把idea激活，不需要使用有期限的激活码. 步骤1.首先下载jetbrains-agent.jar2.在Idea里创建idea.vmoptions3.在idea.vmoptions 填写jetbrains-agent.jar的文件路径4.填写 http://fls.jetbrains-agent.com 最后激活]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[springBoot入门]]></title>
    <url>%2F2019%2F05%2F27%2FspringBoot%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring Boot 是由 Pivotal 团队提供的全新框架，其设计目的是用来简化新 Spring 应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。用我的话来理解，就是 Spring Boot 其实不是什么新的框架，它默认配置了很多框架的使用方式，就像 Maven 整合了所有的 Jar 包，Spring Boot 整合了所有的框架。 特点 为基于spring开发提供更快的入门体检. 开箱即用. springBoot不是对spring的增强，而是提供了更快的使用方式 嵌入式服务器，健康检测，安全、外部配置等非功能性特性. 核心功能 起步依赖将具备某一功能的坐标打包到一起，提供默认的功能 自动配置自动帮你配置某个对象需要的配置,例如tomcat的端口号默认8080等 必须引用的坐标123456789父级依赖&lt;parent&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;relativePath/&gt;&lt;/parent&gt;&lt;/resource&gt; 123456支持web的模块&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件springBoot是基于约定的所有很多配置都有默认值，若想使用自己的配置，可以使用配置文件（properties,yml). 1. propertieskey = value 2. yml（yaml）1234567891011121314151617181920212223242526272829303132331.普通数据的配置（冒号后需要空格）name: zhangsan 2. 对象的配置(同一级别的缩进保持一致)person:name: zhangsanage: 18address: hangzhouserver:port: 80883. 行内对象配置(不常用)person： &#123;name: zhangsan,age: 18, address: hangzhou&#125;4.配置数据集合city:- beijing- hangzhou- taizhou- zhoushancity：[beijing,hangzhou,taizhou]5. 配置对象集合数据student:-name: zhangsanage: 18address: hangzhou-name: lisiage: 16address: taizhou6. map配置map:key1: value1key2: value2 加载配置文件的顺序springBoot一些数据会有默认值，如果你想更改则可以使用配置来覆盖，配置文件后加载的也会覆盖之前加载的.它会先加载yml，最后加载properties. 123456789（spring-boot-starter-parent）&lt;resource&gt;&lt;directory&gt;$&#123;basedir&#125;/src/main/resources&lt;/directory&gt;&lt;excludes&gt;&lt;exclude&gt;**/application*.yml&lt;/exclude&gt;&lt;exclude&gt;**/application*.yaml&lt;/exclude&gt;&lt;exclude&gt;**/application*.properties&lt;/exclude&gt;&lt;/excludes&gt;&lt;/resource&gt; 在业务代码中获取配置信息有如下两种方式： @value(“${name}”) 12@Value(&quot;$&#123;oss.endPoint&#125;&quot;)private String endPoint; 12345oss:endPoint: oss-cn-hangzhou-internal.aliyuncs.comaccessKeyId: ALIYUN_ACCESS_KEYaccessKeySecret: ALIYUN_SECRET_KEYdefaultBucket: salary-prod @ConfigurationProperties(prefix =”person”) 需要set,get方法 12345678910111213141516@Configuration@ConfigurationProperties(prefix = &quot;redis&quot;)public class RedisConfig &#123;private String clusterNodes;private String redisHost;private int redisPort;private String redisPasswd;set()..get()..&#125; 1234567redis:clusterNodes:redisHost: r-bp1d75e29eop202ee4.redis.rds.aliyuncs.comredisPort: 6377redisPasswd: REDIS_PASSWORDtimeout: 3000database: 0]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[excel读写及Zip打包下载]]></title>
    <url>%2F2019%2F01%2F02%2Fexcel%E8%AF%BB%E5%86%99%E5%8F%8AZIp%E6%89%93%E5%8C%85%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[针对2019个税专项附加扣除做的需求：帮助Hr快速收集员工申报信息，及处理信息，由员工填写表单提交信息，对信息进行处理写入到个税局提供的个税专项附加扣除信息excel模版，最后ZIP打包导出. 大致思路首先需要收集处理员工数据，将excel模版放在服务器上，导出时在服务器上创建一个临时文件夹，读取模版excel文件,将数据循环写入excel模版中(一个员工对应一张excel),将写好数据的excel文件流依次写入该文件夹中，接着打包下载该文件夹，最后删除这个临时文件夹. 将excel模版放在服务器上将个税局提供的模版放到服务器上，用于读取 收集处理导出的数据数据是map形式，userId-data,一个员工对应自己的数据 在服务器上创建一个临时文件夹打包时需要一个文件夹存放一个个excel文件 将数据写入循环数据，获取excel模版，创建WorkBook写入数据 处理excel将写好的excel文件命名并写到临时文件夹去 zip打包下载写完所有数据后，对该临时文件夹打包导出 删除文件导出后删除临时文件夹 相关代码主要流程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public static void writeDataToModelExcel(HttpServletRequest request, HttpServletResponse response, Map&lt;String, SalaryTaxExportVO&gt; dataMap, String corpId, String opUserId) throws Exception &#123;final String folderPath = PATH + FILE_NAME_SPECIAL + LINE + corpId + LINE + opUserId + LINE + UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);try &#123;//创建唯一临时文件夹路径//创建扣件单位文件路径集合List&lt;String&gt; companyPathList = Lists.newArrayList();//遍历数据写入excelfor (Map.Entry&lt;String, SalaryTaxExportVO&gt; entry : dataMap.entrySet()) &#123;//获取模版文件excelClassPathResource classPathResource = new ClassPathResource(&quot;xls/latestSalaryTaxDeductTemplate.xls&quot;);//LOGGER.warn(&quot;qqqqq&quot; + Cipher.getMaxAllowedKeyLength(&quot;AES&quot;));Workbook wb = WorkbookFactory.create(classPathResource.getInputStream());//3.获取数据SalaryTaxExportVO salaryTaxExportVO = entry.getValue();String userId = salaryTaxExportVO.getUserId();//将数据写到excel模版中writeDataToTemplate(salaryTaxExportVO, wb);//将文件写入服务器(创建临时文件夹)File newFile = new File(folderPath);if (!newFile.exists()) &#123;boolean mkdirs = newFile.mkdirs();if (!mkdirs) &#123;throw new ExcelException(&quot;文件路径生成失败&quot;);&#125;&#125;//获取扣缴单位名称 地区 身份证String companyName = salaryTaxExportVO.getCompanyName();if(StringUtils.isBlank(companyName))&#123;companyName = &quot;无扣缴单位&quot;;&#125;String area = salaryTaxExportVO.getArea();String certNo = salaryTaxExportVO.getCertNo();//创建扣缴单位文件路径String companyPath = folderPath + SYMBOL + companyName + SYMBOL;if (!companyPathList.contains(companyPath)) &#123;File file = new File(companyPath);if (!file.exists()) &#123;file.mkdirs();&#125;companyPathList.add(companyPath);&#125;// 向扣缴单位文件夹写文件 地区+扣缴单位名称+个人身份号码List&lt;String&gt; names = Lists.newArrayList();names.add(area);names.add(companyName);names.add(certNo);names.add(&quot;.xls&quot;);String fileName = StringUtils.join(names.stream().filter(Objects::nonNull).collect(Collectors.toList()), &quot;&quot;);FileOutputStream out = new FileOutputStream(companyPath + fileName);wb.write(out);wb.close();&#125;// 获取zip文件名称 （余杭、建德）+扣缴单位名称String folderName = &quot;个人所得税专项附加扣除申报文件.zip&quot;;//打包下载文件packToDownload(request, response, folderName, folderPath);&#125; catch (Exception e) &#123;LOGGER.error(&quot;writeDataToModelExcel error, corpId=&#123;&#125;, userId=&#123;&#125;.&quot;, corpId, opUserId,e);throw e;&#125; finally &#123;// 删除文件delFolder(folderPath);&#125;&#125; 创建zip包123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/*** 创建ZIP文件** @param folderPath 文件或文件夹路径*/private static void packToDownload(HttpServletRequest request, HttpServletResponse response, String folderName, String folderPath) &#123;try (ServletOutputStream outputStream = response.getOutputStream();ZipOutputStream zos = new ZipOutputStream(outputStream)) &#123;//设置响应头,必须在写文件前DownloadUtil.setFileDownloadHeader(request, response, folderName);writeZip(new File(folderPath), &quot;&quot;, zos);&#125; catch (Exception e) &#123;LOGGER.error(&quot;TaxDeductExcelUtil packToDownload 创建ZIP文件失败&quot;, e);&#125;&#125;/****写文件*/private static void writeZip(File file, String parentPath, ZipOutputStream zos) &#123;if (file.exists()) &#123;if (file.isDirectory()) &#123;//处理文件夹String filename = file.getName();if (filename.contains(FILE_NAME_SPECIAL))&#123;filename = &quot;个人所得税专项附加扣除申报文件&quot;;&#125;parentPath += filename + File.separator;File[] files = file.listFiles();if (files.length != 0) &#123;for (File f : files) &#123;writeZip(f, parentPath, zos);&#125;&#125; else &#123; //空目录则创建当前目录try &#123;zos.putNextEntry(new ZipEntry(parentPath));&#125; catch (IOException e) &#123;LOGGER.error(&quot;TaxDeductExcelUtil packToDownload 创建ZIP文件失败&quot;, e);&#125;&#125;&#125; else &#123;FileInputStream fis = null;try &#123;fis = new FileInputStream(file);ZipEntry ze = new ZipEntry(parentPath + file.getName());zos.putNextEntry(ze);byte[] content = new byte[1024];int len;while ((len = fis.read(content)) != -1) &#123;zos.write(content, 0, len);zos.flush();&#125;&#125; catch (Exception e) &#123;LOGGER.error(&quot;TaxDeductExcelUtil packToDownload 创建ZIP文件失败&quot;, e);&#125; finally &#123;try &#123;if (fis != null) &#123;fis.close();&#125;&#125; catch (Exception e) &#123;LOGGER.error(&quot;TaxDeductExcelUtil packToDownload 创建ZIP文件失败&quot;, e);&#125;&#125;&#125;&#125;&#125;/****设置响应头*/public static void setFileDownloadHeader(HttpServletRequest request, HttpServletResponse response, String fileName) &#123;final String userAgent = request.getHeader(&quot;User-Agent&quot;);try &#123;String finalFileName = getEncodeFileName(userAgent, fileName);response.setContentType(&quot;application/octet-stream&quot;);response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment; &quot; + finalFileName);&#125; catch (Exception ignored) &#123;&#125;&#125; 删除文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*** 删除文件** @param folderPath* @return*/private static void delFolder(String folderPath) &#123;try &#123;//删除完里面所有内容delAllFile(folderPath);java.io.File myFilePath = new java.io.File(folderPath);//删除空文件夹myFilePath.delete();&#125; catch (Exception e) &#123;LOGGER.error(&quot;TaxDeductExcelUtil delFolder 删除文件失败&quot;, e);&#125;&#125;private static boolean delAllFile(String path) &#123;boolean flag = false;File file = new File(path);if (!file.exists()) &#123;return false;&#125;if (!file.isDirectory()) &#123;return false;&#125;String[] tempList = file.list();if (ArrayUtils.isEmpty(tempList)) &#123;return true;&#125;for (String aTempList : tempList) &#123;File temp;if (path.endsWith(File.separator)) &#123;temp = new File(path + aTempList);&#125; else &#123;temp = new File(path + File.separator + aTempList);&#125;if (temp.isFile()) &#123;temp.delete();&#125;if (temp.isDirectory()) &#123;//先删除文件夹里面的文件delAllFile(path + &quot;/&quot; + aTempList);//再删除空文件夹delFolder(path + &quot;/&quot; + aTempList);flag = true;&#125;&#125;return flag;&#125; 注意点 创建临时文件时，一定要保证文件名唯一（防止同一时间并发，导出串数据），这里采用了corpId-userId-UUID 后缀.xls表示07之前的版本 使用HSSFWookBook，.xlsx是07之后的版本XSSFWookBook，这里使用POI兼容的方式，自动帮你识别：Workbook wb = WorkbookFactory.create(classPathResource.getInputStream())； 在循环中每写完一个excel都要关流 wb.close() — 因为是多个excel 最后一定要删除服务器上的文件（防止文件堆积占用内存） HSSF对excel函数方法较多不支持导致导出的文件一些版本的excel内容不可读，不过用WPS可以正常打开 设置响应头,必须在写文件前 JCE策略文件-读取excel加密文件时，jdk版本需要在”1.8.0_161以上，否则需要安装第三方jar包（US_export_policy.jar , local_policy.jar ）]]></content>
      <categories>
        <category>Java开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[maven基本知识]]></title>
    <url>%2F2018%2F12%2F23%2Fmaven%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[maven是项目管理工具，主要有两个特性: 依赖管理和一键构建. 依赖管理依赖管理就是对jar包的管理过程.传统的工程项目是直接放置jar包，maven工程真正的jar包在仓库中放置，项目中只放置jar包的坐标(pom.xml). 仓库分三类 ：本地仓库,远程仓库【私服】,中央仓库.本地仓库是我们运行项目第一步必须本地仓库有对应的坐标，如果没有默认自动去中央仓库下载，在公司中会先从远程仓库下载，远程仓库没有，会从中央仓库下载或本地上传. 1234567891011121314151617&lt;project ….&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.dintalent.salary&lt;/groupId&gt; &lt;artifactId&gt;mavenDemo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;mavenDemo&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt;&lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt; groupId : 标识公司,组织,团体(taobao.com对应com.taobao,apche.org对应org.apache) artifactId ：工程名 version :版本号 （SNAPSHOT表示测试版本） packaging ： 打成什么包(jar,war,pom) scope : 依赖范围（例如test 表示对测试代码classpath有效） 一键构建一键构建就是我们使用maven集成的tomcat插件对项目进行编译，测试，打包，安装等操作. 清理生命周期：clean 默认生命周期：compile(编译),test(测试),package(打包),install(安装). jar包冲突问题简单理解就是应用程序依赖的同一个jar包出现了多个不同的版本，选择了错误的版本导致JVM加载不到类或加载了错误版本的类. 直接依赖： A项目导入了B包，A直接依赖B包 传递依赖： A项目导入了B包，B包直接依赖C包，最终A可以使用C 解决jar冲突的三个原则 第一声明原则：哪个jar包的坐标靠上，这个jar包就是第一声明的包，最终进入项目的就是它. 路径近者优先原则：直接依赖路径比传递依赖近，进入项目的就是路径近的. 直接排除法： 使用标签直接排除某个包的依赖包.]]></content>
      <categories>
        <category>Maven</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[自定义注解简单使用]]></title>
    <url>%2F2018%2F10%2F21%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[需要对一些用户行为的接口进行日志埋点统计,如果在业务代码写的话代码比较杂乱,而且之后改动也不方便,于是便决定使用自定义注解，使用spring的切面注解@Aspect. 注解的定义Java文件叫做Annotation，用@interface表示。 元注解@interface上面按需要注解上一些东西，包括@Retention、@Target、@Document、@Inherited四种. @Target 表示该注解可以用于什么地方 @Retention 注解的声明周期，用于定义注解的存活阶段，可以存活在源码级别、编译级别(字节码级别)、运行时级别 @Document 将注解包含在Javadoc中 @Inherited 允许子类继承父类中的注解 自定义注解 基于注解的知识，自己创建一个注解 实现过程首先创建一个自定义注解 -&gt; 采用spring的@Aspect创建一个切面类,在这个切中获取信息并且打印日志 -&gt; 在记录的接口上写上注解 简单示例代码 参考：项目中的操作日志的方法]]></content>
      <categories>
        <category>Java开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性Lambda和Stream]]></title>
    <url>%2F2018%2F09%2F18%2FJava8%E6%96%B0%E7%89%B9%E6%80%A7Lambda%E5%92%8CStream%2F</url>
    <content type="text"><![CDATA[目前项目应用的是Java 1.8版本,在项目中看到其他小伙伴使用了奇特的编码方式，许多行代码简化成了一行，原来是Java8的特性Lambda和Stream,结合代码和网上查资料学习了一下，并将相关的的知识做了下总结. lambda表达式lambda简单的理解就是一个匿名方法，一段带有输入参数的可执行语句块. 语法：（）-&gt; {} (小括号里是参数，大括号里是方法体) 特点：1.参数类型可以省略，编译器可以从上下文环境中推断出来 2.当lambda表达式的参数个数只有一个的时候，小括号可以省略 3.当lambda表达式只包含一条语句时，可以省略大括号，return，语句结尾的分号 4.lambda表达式可以访问外部变量，但是要求这个变量不可变（final修饰） 方法引用：1.类实例引用： Person::getName 2.类静态方法引用：Max::max 构造器引用：Person::new（等同于 x-&gt;new Person(x)） StreamStream（流）是一个来自数据源的元素队列并支持聚合操作。数据源一般是数组或集合等，进行聚合操作可以获取想要的结果。 基本步骤：获取一个数据源（source）-&gt; 数据转化 -&gt; 执行操作获取想要的结果.(简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果) 创建Stream1.Stream静态方法：Stream.of(); 2.Collection子类获取Stream（最常用）：list.Stream(); Stream流操作 *Intermediate（中间）: 一个流可以跟多个中间操作，主要是打开流对数据进行某种映射或过滤.常见操作: map() - 对stream里的元素进行映射转化 filter() - 对Stream包含对元素按给定的条件过滤 distinct() - 对stream包含对元素进行去重 sorted() - 对stream包含对元素排序 peek() - 生成一个包含原Stream的所有元素的新Stream，同时会提供一个消费函数（Consumer实例），新Stream每个元素被消费的时候都会执行给定的消费函数 limit() - 对Stream里的元素取前n个 skip(n) - 对stream里的元素丢弃前n个，获取之后的元素 parallel() - 将一个顺序执行的流转变成一个并发的流（还有一种Collection.parallelStream()） sequential() - 一个并行流转换成一个顺序流 unordered() - 实现无序流 Terminal(终端): 一个流只能有一个终端操作，这是流对最后一个操作，用来处理结果数据。常见操作: forEach() - 遍历结果数据（并行处理） forEachOrdered - 遍历结果数据（顺序处理） toArray（） - 将数据输入到数组中 reduce（） - 把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合 collect（） - 实现了很多归约操作，例如将流转换成集合和聚合元素 count() - 获取stream里的元素个数 min() - 最小值 max() - 最大值 anyMatch() - Stream中是否存在任何一个元素满足匹配条件 allMatch() - 是不是Stream中的所有元素都满足给定的匹配条件 noneMatch() - 是不是Stream中的所有元素都不满足给定的匹配条件 findFirst() - 返回Stream中的第一个元素，如果Stream为空，返回空Optional findAny() - 返回这个Stream中，取到的任何一个对象 简单示例代码 七牛云大坑逼！！！！！ 参考：https://yuque.antfin-inc.com/mdc/doc/rhihn7]]></content>
      <categories>
        <category>Java开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac系统Idea常用快捷键]]></title>
    <url>%2F2018%2F09%2F09%2FMac%E7%B3%BB%E7%BB%9F%E4%B8%8BIdea%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[之前一直使用的Java编译工具是eclipse,进新公司之后,公司配了一台Mac并且后端都用IntelliJ IDEA开发,不能脱离团队呀,果断入手了IDEA,不得不说比eclipse更加的智能好用,为了提高开发效率，所以决定整理一下IDEA的常用快捷键,不想每次都配,所以就决定用IDEA默认的快捷键,用的是Mac OS X 10.5+ 但是Mac系统中与IDEA的快捷键有些冲突,可以把Mac相关冲突的快捷键更改或取消掉.下面整理了平常开发中常用的快捷键，以便于更好的记忆和熟练使用. Mac键盘符号和修饰健说明⌘ Command⇧ Shift⌥ Option⌃ Control↩︎ Return/Enter⌫ Delete⌦ 向前删除键（Fn+Delete）↑ 上箭头↓ 下箭头← 左箭头→ 右箭头⇞ Page Up（Fn+↑）⇟ Page Down（Fn+↓）Home Fn + ←End Fn + →⇥ 右制表符（Tab键）⇤ 左制表符（Shift+Tab）⎋ Escape (Esc) Editing编辑123456789101112131415161718192021222324252627282930Control+Space 基本的代码补全(补全任何类,方法,变量) 注意这里与Mac系统的输入法快捷键冲突Control+Shift+Space 智能代码补全 (过滤器方法列表和变量的预期类型）Command+Shift+Enter 自动结束代码,行末添加分号Command+P 显示方法的参数Control+J 快速显示文档Command+鼠标放在代码上 显示代码简要信息Command+N 生成代码（getter、setter、构造函数、hashCode/equals,toString,实现接口方法）这个还有其他快捷键我只记这一种了Control+O 覆盖方法(重写父类方法)Control+I 实现接口方法(我直接记Command+N,也能实现接口方法)Command+Option+T 包围代码(try catch,if else,do while等)Command+/ 行注释代码(再按一次就是取消注释)Command+Option+/ 块注释Option+方向上 连续选中代码块Option+方向下 减少选中的代码块Control+Shift+Q 显示上下文信息Option+Enter 显示意向动作和快速修复代码Command+Option+L 格式化代码Control+Option+O 优化importTab 缩进代码Command+C 复制Command+V 粘贴Command+X 剪切Command+D 复制当前行或选定的块Command+Delete 删除当前行或选定的行的块Control+Shift+J 智能的将代码拼接成一行Command+Enter 智能的拆分拼接的行Command+加号/减号 展开/折叠代码块Command+Shift+加号/减号 展开/折叠所有代码块Command+W 关闭活动的编辑器选项Command+Shift+上下 上下移动代码 Search/Replace（查询/替换)1234Command+F 文件内查找Command+Shift+F 全局查找Command+G 查找模式下向下查找Command+Shift+G 查找模式下向上查找 Usage Search（使用查询）1234Option+F7 在文件中查找用到的地方Command+F7 在类中查找用到的地方Command+Shift+F7 在类中显示(颜色标记)用到的地方Command+Option+F7 显示用法 Compile and Run（编译和运行）12345Command+F9 编译ProjectCommand+Shift+F9 编译选择的文件,包或模块Control+Option+R 弹出Run的可选菜单Control+Option+R 弹出Debug的可选菜单Control+D 调试 Debug调试123456F8 进入下一步,不进入当前方法内F7 进入下一步,如果当前断点式方法,则进入方法内Shift+F8 跳出Option+F9 运行到光标停留处F9 放开debug Command+Shift+F8 查看断点信息 Navigation（导航）123456Shift+Shift 查找文件Command+L 跳转行Command+E 显示最近打开的文件记录列表Command+Option+方向键左/右 退回/前进到上一个操作的地方Command+B 或Command+鼠标左键 进入方法或变量的接口或是定义处Command+Option+B 越过接口,直接跳掉实现处 Refactoring（重构）1234F5 复制文件到指定目录Command+delete 在文件上安全删除文件,弹出确认框Shift+F6 重命名文件Command+Option+M 将选中的代码提取为方法 General（通用）1Command+, 打开idea系统设置]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
  </entry>
</search>
